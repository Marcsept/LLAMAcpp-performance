{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d8b6db",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: blue;\">\n",
    "    <h1>Visualisation, options llama on GPT2</h1>\n",
    "</div>\n",
    "\n",
    "**Nom :** BILLAUD Val√®re\n",
    "\n",
    "**Date :** 22/05/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7b9b0",
   "metadata": {},
   "source": [
    "# 1) Global"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b69b3a",
   "metadata": {},
   "source": [
    "## 1) Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e138e388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6313542",
   "metadata": {},
   "source": [
    "## 2) Some function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c4c39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datanalyse(df, name_option):\n",
    "    #Calcule mean_load_time\n",
    "    mean_load_time = df['load_time'].str.replace(\"ms\", \"\").astype(float).mean()\n",
    "    #Calcule mean_sample_token_per_seconde\n",
    "    mean_sample_token_per_seconde = df['token_per_sec'].astype(float).mean()\n",
    "    #Calcule mean_prompt_eval_time_token_per_seconde\n",
    "    mean_prompt_eval_time_token_per_seconde = df['token_per_sec.1'].astype(float).mean()\n",
    "    #Calcule mean_eval_time_token_per_seconde\n",
    "    mean_eval_time_token_per_seconde = df['token_per_sec.2'].astype(float).mean()\n",
    "    #Calcule mean_total_time_token_per_seconde\n",
    "    mean_total_time_token_per_seconde=0\n",
    "    step1_mean_total_time_token_per_seconde= df['total_time'].str.replace(\"ms\", \"\").str.replace(\"tokens\",\"\")\n",
    "    step2_mean_total_time_token_per_seconde = [x.split(\"/\") for x in step1_mean_total_time_token_per_seconde]\n",
    "    step3_mean_total_time_token_per_seconde = [ 1000 / (float(x[0]) / float(x[1])) for x in step2_mean_total_time_token_per_seconde]\n",
    "    for x in step3_mean_total_time_token_per_seconde :\n",
    "        mean_total_time_token_per_seconde += x\n",
    "    mean_total_time_token_per_seconde = mean_total_time_token_per_seconde / len(step3_mean_total_time_token_per_seconde)\n",
    "   \n",
    "    return [name_option,\n",
    "            round(mean_load_time,3),\n",
    "            round(mean_sample_token_per_seconde,3),\n",
    "            round(mean_prompt_eval_time_token_per_seconde,3),\n",
    "            round(mean_eval_time_token_per_seconde,3),\n",
    "            round(mean_total_time_token_per_seconde,3)]\n",
    "\n",
    "def stock(tab):\n",
    "    to_write = \"\"\n",
    "    for i in tab:\n",
    "        to_write+= str(i) + \";\"\n",
    "    to_write = to_write[:-1]+\"\\n\"\n",
    "    with open('summerize.csv', 'a') as fichier:\n",
    "        fichier.write(to_write)\n",
    "        \n",
    "def preparation_data(dataFrame, name_option):\n",
    "    stock(datanalyse(dataFrame, name_option))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c0c699",
   "metadata": {},
   "source": [
    "## 3) Merge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121efd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colums= [\"Option\",\"mean_load_time\",\"mean_sample_token_per_seconde\",\"mean_prompt_eval_time_token_per_seconde\",\"mean_eval_time_token_per_seconde\",\"mean_total_time_token_per_seconde\"]\n",
    "if os.path.exists(\"summerize.csv\"):\n",
    "    os.remove(\"summerize.csv\")\n",
    "stock(colums)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9df99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_only_aggregation.csv\n",
    "preparation_data(pd.read_csv(\"gpt2_test_input_only_aggregation.csv\", sep=';', encoding='latin1'), \"without option\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93586714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_ctk_ctv_aggregation.csv\n",
    "def f32(string):\n",
    "    return \"_f32_\" in string\n",
    "def f16(string):\n",
    "    return \"_f16_\" in string\n",
    "#option type f32 in cache for K and V\n",
    "df = pd.read_csv(\"gpt2_test_input_ctv_ctk_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_ctv_ctk_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(f32)]\n",
    "name_option = \"KV_f32\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option type f16 in cache for K and V\n",
    "df = pd.read_csv(\"gpt2_test_input_ctv_ctk_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_ctv_ctk_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(f16)]\n",
    "name_option = \"KV_f16\"\n",
    "preparation_data(df,name_option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fa672f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_grp_att_aggregation.csv\n",
    "\n",
    "def n(string):\n",
    "    return \"att_n_\" in string\n",
    "def w(string):\n",
    "    return \"att_w_\" in string\n",
    "def nw(string):\n",
    "    return \"att_w_n\" in string\n",
    "\n",
    "#option group attention factor 2 (default 1)\n",
    "df = pd.read_csv(\"gpt2_test_input_grp_att_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_grp_att_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(n)]\n",
    "name_option = \"grp_att_factor_2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option groupe attention width 256 (default 256)\n",
    "df = pd.read_csv(\"gpt2_test_input_grp_att_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_grp_att_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(w)]\n",
    "name_option = \"grp_att_width_256\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option group attention factore 2 and groupe attention width 256\n",
    "df = pd.read_csv(\"gpt2_test_input_grp_att_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_grp_att_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(nw)]\n",
    "name_option = \"grp_att_factor_width\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a5d52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_keep_aggregation.csv\n",
    "\n",
    "def zero(string):\n",
    "    return \"_0_\" in string\n",
    "def twenty(string):\n",
    "    return \"_20_\" in string\n",
    "def all_(string):\n",
    "    return \"_all_\" in string\n",
    "\n",
    "#option number of tokens to keep from the initial prompt 0 (default : 0)\n",
    "df = pd.read_csv(\"gpt2_test_input_keep_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_keep_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(zero)]\n",
    "name_option = \"keep_0\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option number of tokens to keep from the initial prompt 20 (default : 0)\n",
    "df = pd.read_csv(\"gpt2_test_input_keep_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_keep_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(twenty)]\n",
    "name_option = \"keep_20\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option number of tokens to keep from the initial prompt -1 (all) (default : 0)\n",
    "df = pd.read_csv(\"gpt2_test_input_keep_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_keep_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(all_)]\n",
    "name_option = \"keep_all\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4baaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_min-p_aggregation.csv\n",
    "\n",
    "def one(string):\n",
    "    return \"_01_\" in string\n",
    "def ten(string):\n",
    "    return \"_05_\" in string\n",
    "def thirty(string):\n",
    "    return \"_99_\" in string\n",
    "\n",
    "#option min probability sampling 0.01 (default : 0.1)\n",
    "df = pd.read_csv(\"gpt2_test_input_min-p_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_min-p_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(one)]\n",
    "name_option = \"min-p 0.01\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option min probability sampling 0.1 (default : 0.1)\n",
    "df = pd.read_csv(\"gpt2_test_input_min-p_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_min-p_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(ten)]\n",
    "name_option = \"min-p 0.1\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option min probability sampling 0.3 (default : 0.1)\n",
    "df = pd.read_csv(\"gpt2_test_input_min-p_aggregation.csv\", sep=';', encoding='latin1')[pd.read_csv(\"gpt2_test_input_min-p_aggregation.csv\", sep=';', encoding='latin1')['name_'].apply(thirty)]\n",
    "name_option = \"min-p 0.3\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c6a6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_mirostat_aggregation.csv\n",
    "\n",
    "def _mirostat1_br002_ent15(string):\n",
    "    return \"_mirostat1_br002_ent15\" in string\n",
    "def _mirostat1_br002_ent2(string):\n",
    "    return \"_mirostat1_br002_ent2\" in string\n",
    "def _mirostat1_br002_ent5(string):\n",
    "    return \"_mirostat1_br002_ent5\" in string\n",
    "def _mirostat1_br002_ent8(string):\n",
    "    return \"_mirostat1_br002_ent8\" in string\n",
    "\n",
    "def _mirostat1_br02_ent15(string):\n",
    "    return \"_mirostat1_br02_ent15\" in string\n",
    "def _mirostat1_br02_ent2(string):\n",
    "    return \"_mirostat1_br02_ent2\" in string\n",
    "def _mirostat1_br02_ent5(string):\n",
    "    return \"_mirostat1_br02_ent5\" in string\n",
    "def _mirostat1_br02_ent8(string):\n",
    "    return \"_mirostat1_br02_ent8\" in string\n",
    "\n",
    "def _mirostat1_br05_ent15(string):\n",
    "    return \"_mirostat1_br05_ent15\" in string\n",
    "def _mirostat1_br05_ent2(string):\n",
    "    return \"_mirostat1_br05_ent2\" in string\n",
    "def _mirostat1_br05_ent5(string):\n",
    "    return \"_mirostat1_br05_ent5\" in string\n",
    "def _mirostat1_br05_ent8(string):\n",
    "    return \"_mirostat1_br05_ent8\" in string\n",
    "\n",
    "\n",
    "def _mirostat2_br002_ent15(string):\n",
    "    return \"_mirostat2_br002_ent15\" in string\n",
    "def _mirostat2_br002_ent2(string):\n",
    "    return \"_mirostat2_br002_ent2\" in string\n",
    "def _mirostat2_br002_ent5(string):\n",
    "    return \"_mirostat2_br002_ent5\" in string\n",
    "def _mirostat2_br002_ent8(string):\n",
    "    return \"_mirostat2_br002_ent8\" in string\n",
    "\n",
    "def _mirostat2_br02_ent15(string):\n",
    "    return \"_mirostat2_br02_ent15\" in string\n",
    "def _mirostat2_br02_ent2(string):\n",
    "    return \"_mirostat2_br02_ent2\" in string\n",
    "def _mirostat2_br02_ent5(string):\n",
    "    return \"_mirostat2_br02_ent5\" in string\n",
    "def _mirostat2_br02_ent8(string):\n",
    "    return \"_mirostat2_br02_ent8\" in string\n",
    "\n",
    "def _mirostat2_br05_ent15(string):\n",
    "    return \"_mirostat2_br05_ent15\" in string\n",
    "def _mirostat2_br05_ent2(string):\n",
    "    return \"_mirostat2_br05_ent2\" in string\n",
    "def _mirostat2_br05_ent5(string):\n",
    "    return \"_mirostat2_br05_ent5\" in string\n",
    "def _mirostat2_br05_ent8(string):\n",
    "    return \"_mirostat2_br05_ent8\" in string\n",
    "\n",
    "csv = \"gpt2_test_input_mirostat_aggregation.csv\"\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 15 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br002_ent15)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 2 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br002_ent2)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 5 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br002_ent5)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 8 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br002_ent8)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 15 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br02_ent15)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 2 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br02_ent2)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 5 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br02_ent5)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 8 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br02_ent8)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 15 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br05_ent15)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 2 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br05_ent2)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 5 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br05_ent5)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V1 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 8 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat1_br05_ent8)]\n",
    "name_option = \"mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 15 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br002_ent15)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 2 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br002_ent2)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 5 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br002_ent5)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.02 (default : 0.1)\n",
    "#option mirostat entropy : 8 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br002_ent8)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 15 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br02_ent15)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 2 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br02_ent2)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 5 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br02_ent5)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.2 (default : 0.1)\n",
    "#option mirostat entropy : 8 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br02_ent8)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 15 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br05_ent15)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 2 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br05_ent2)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 5 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br05_ent5)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option mirostat : V2 (default : not use) \n",
    "#option mirostat learning rate : 0.5 (default : 0.1)\n",
    "#option mirostat entropy : 8 (default : 5)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_mirostat2_br05_ent8)]\n",
    "name_option = \"mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea1c603d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_nkvo_aggregation.csv\n",
    "def nkvo(string):\n",
    "    return \"nkvo\" in string\n",
    "def not_nkvo(string):\n",
    "    return not nkvo(string)\n",
    "\n",
    "csv=\"gpt2_test_input_nkvo_aggregation.csv\"\n",
    "\n",
    "#option disable KV offload\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(nkvo)]\n",
    "name_option = \"disable KV offload\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#without option\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(not_nkvo)]\n",
    "name_option = \"Normal\"\n",
    "preparation_data(df,name_option)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9ce4a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_repeat_last_n_aggregation.csv\n",
    "def _0(string):\n",
    "    return \"_0_\" in string\n",
    "def _32(string):\n",
    "    return \"_32_\" in string\n",
    "def _128(string):\n",
    "    return \"_128_\" in string\n",
    "def _all(string):\n",
    "    return \"_all_\" in string\n",
    "\n",
    "csv=\"gpt2_test_input_repeat_last_n_aggregation.csv\"\n",
    "\n",
    "#option last n tokens to consider for penalize : 0 (default : 64)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_0)]\n",
    "name_option = \"repeat last n : 0\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option last n tokens to consider for penalize : 32 (default : 64)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_32)]\n",
    "name_option = \"repeat last n : 32\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option last n tokens to consider for penalize : 128 (default : 64)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_128)]\n",
    "name_option = \"repeat last n : 128\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option last n tokens to consider for penalize : context file (default : 64)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_all)]\n",
    "name_option = \"repeat last n : context file\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d327206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_repeat_penalty_aggregation.csv\n",
    "def _1(string):\n",
    "    return \"_1_\" in string\n",
    "def _1_5(string):\n",
    "    return \"_1.5_\" in string\n",
    "def _20(string):\n",
    "    return \"_20_\" in string\n",
    "\n",
    "\n",
    "csv=\"gpt2_test_input_repeat_penalty_aggregation.csv\"\n",
    "\n",
    "#option penalize repeat sequence of tokens : 1 (default : 1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_1)]\n",
    "name_option = \"repeat penalty : 1\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option penalize repeat sequence of tokens : 1.5 (default : 1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_1_5)]\n",
    "name_option = \"repeat penalty : 1.5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option penalize repeat sequence of tokens : 20 (default : 1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_20)]\n",
    "name_option = \"repeat penalty n : 20\"\n",
    "preparation_data(df,name_option)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfc4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_split_aggregation.csv\n",
    "def _np01_ns10_ps10_(string):\n",
    "    return \"_np01_ns10_ps10_\" in string\n",
    "def _np01_ns10_ps1_(string):\n",
    "    return \"_np01_ns10_ps1_\" in string\n",
    "def _np01_ns10_ps2_(string):\n",
    "    return \"_np01_ns10_ps2_\" in string\n",
    "def _np01_ns1_ps10(string):\n",
    "    return \"_np01_ns1_ps10_\" in string\n",
    "def _np01_ns1_ps1_(string):\n",
    "    return \"_np01_ns1_ps1_\" in string\n",
    "def _np01_ns1_ps2_(string):\n",
    "    return \"_np01_ns1_ps2_\" in string\n",
    "def _np01_ns2_ps10_(string):\n",
    "    return \"_np01_ns2_ps10_\" in string\n",
    "def _np01_ns2_ps1_(string):\n",
    "    return \"_np01_ns2_ps1_\" in string\n",
    "def _np01_ns2_ps2_(string):\n",
    "    return \"_np01_ns2_ps2_\" in string\n",
    "def _np05_ns10_ps10_(string):\n",
    "    return \"_np05_ns10_ps10_\" in string\n",
    "def _np05_ns10_ps1_(string):\n",
    "    return \"_np05_ns10_ps1_\" in string\n",
    "def _np05_ns10_ps2_(string):\n",
    "    return \"_np05_ns10_ps2_\" in string\n",
    "def _np05_ns1_ps10_(string):\n",
    "    return \"_np05_ns1_ps10_\" in string\n",
    "def _np05_ns1_ps1_(string):\n",
    "    return \"_np05_ns1_ps1_\" in string\n",
    "def _np05_ns1_ps2_(string):\n",
    "    return \"_np05_ns1_ps2_\" in string\n",
    "def _np05_ns2_ps10_(string):\n",
    "    return \"_np05_ns2_ps10_\" in string\n",
    "def _np05_ns2_ps1_(string):\n",
    "    return \"_np05_ns2_ps1_\" in string\n",
    "def _np05_ns2_ps2_(string):\n",
    "    return \"_np05_ns2_ps2_\" in string\n",
    "def _np09_ns10_ps10(string):\n",
    "    return \"_np09_ns10_ps10\" in string\n",
    "def _np09_ns10_ps1_(string):\n",
    "    return \"_np09_ns10_ps1_\" in string\n",
    "def _np09_ns10_ps2_(string):\n",
    "    return \"_np09_ns10_ps2_\" in string\n",
    "def _np09_ns1_ps10_(string):\n",
    "    return \"_np09_ns1_ps10_\" in string\n",
    "def _np09_ns1_ps1_(string):\n",
    "    return \"_np09_ns1_ps1_\" in string\n",
    "def _np09_ns1_ps2_(string):\n",
    "    return \"_np09_ns1_ps2_\" in string\n",
    "def _np09_ns2_ps10_(string):\n",
    "    return \"_np09_ns2_ps10_\" in string\n",
    "def _np09_ns2_ps1(string):\n",
    "    return \"_np09_ns2_ps1\" in string\n",
    "def _np09_ns2_ps2(string):\n",
    "    return \"_np09_ns2_ps2\" in string\n",
    "\n",
    "csv=\"gpt2_test_input_split_aggregation.csv\"\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns10_ps10_)]\n",
    "name_option = \"_np01_ns10_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns10_ps1_)]\n",
    "name_option = \"_np01_ns10_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns10_ps2_)]\n",
    "name_option = \"_np01_ns10_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns1_ps10)]\n",
    "name_option = \"_np01_ns1_ps10\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns1_ps1_)]\n",
    "name_option = \"_np01_ns1_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns1_ps2_)]\n",
    "name_option = \"_np01_ns1_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns2_ps10_)]\n",
    "name_option = \"_np01_ns2_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns2_ps1_)]\n",
    "name_option = \"_np01_ns2_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np01_ns2_ps2_)]\n",
    "name_option = \"_np01_ns2_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns10_ps10_)]\n",
    "name_option = \"_np05_ns10_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns10_ps1_)]\n",
    "name_option = \"_np05_ns10_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns10_ps2_)]\n",
    "name_option = \"_np05_ns10_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns1_ps10_)]\n",
    "name_option = \"_np05_ns1_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns1_ps1_)]\n",
    "name_option = \"_np05_ns1_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns1_ps2_)]\n",
    "name_option = \"_np05_ns1_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns2_ps10_)]\n",
    "name_option = \"_np05_ns2_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns2_ps1_)]\n",
    "name_option = \"_np05_ns2_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np05_ns2_ps2_)]\n",
    "name_option = \"_np05_ns2_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns10_ps10)]\n",
    "name_option = \"_np09_ns10_ps10\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns10_ps1_)]\n",
    "name_option = \"_np09_ns10_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns10_ps2_)]\n",
    "name_option = \"_np09_ns10_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns1_ps10_)]\n",
    "name_option = \"_np09_ns1_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns1_ps1_)]\n",
    "name_option = \"_np09_ns1_ps1_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns1_ps2_)]\n",
    "name_option = \"_np09_ns1_ps2_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns2_ps10_)]\n",
    "name_option = \"_np09_ns2_ps10_\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns2_ps1)]\n",
    "name_option = \"_np09_ns2_ps1\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option   -np N, --parallel N   number of parallel sequences to decode (default: 1)\n",
    "#option   -ns N, --sequences N  number of sequences to decode (default: 1)\n",
    "#option   -ps N, --p-split N    speculative decoding split probability (default: 0.1)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_np09_ns2_ps2)]\n",
    "name_option = \"_np09_ns2_ps2\"\n",
    "preparation_data(df,name_option)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e7a177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_temp_aggregation.csv\n",
    "def _0(string):\n",
    "    return \"0_\" in string\n",
    "def _0_5(string):\n",
    "    return \"05_\" in string\n",
    "def _5(string):\n",
    "    return \"5_\" in string\n",
    "\n",
    "\n",
    "csv=\"gpt2_test_input_temp_aggregation.csv\"\n",
    "\n",
    "#option temp : 0 (default : 0.8)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_0)]\n",
    "name_option = \"temp : 0\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option temp : 0.5 (default : 0.8)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_0_5)]\n",
    "name_option = \"temp : 0.5\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option temp : 5 (default : 0.8)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_5)]\n",
    "name_option = \"temp : 5\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ed1f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_tfs_aggregation.csv\n",
    "def _10(string):\n",
    "    return \"_10_\" in string\n",
    "def _60(string):\n",
    "    return \"_60_\" in string\n",
    "def _80(string):\n",
    "    return \"_80_\" in string\n",
    "def _90(string):\n",
    "    return \"_90_\" in string\n",
    "def _95(string):\n",
    "    return \"_95_\" in string\n",
    "def _100(string):\n",
    "    return \"_100_\" in string\n",
    "\n",
    "\n",
    "csv=\"gpt2_test_input_tfs_aggregation.csv\"\n",
    "\n",
    "#option tail free sampling : 0.1 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_10)]\n",
    "name_option = \"tfs : 0.1\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option tail free sampling : 0.6 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_60)]\n",
    "name_option = \"tfs : 0.6\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option tail free sampling : 0.8 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_80)]\n",
    "name_option = \"tfs : 0.8\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option tail free sampling : 0.9 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_90)]\n",
    "name_option = \"tfs : 0.9\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option tail free sampling : 0.95 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_95)]\n",
    "name_option = \"tfs : 0.95\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option tail free sampling : & (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_100)]\n",
    "name_option = \"tfs : 1 disabled\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff0bc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_thraed_aggregation.csv\n",
    "def _1(string):\n",
    "    return \"_thread1_\" in string\n",
    "def _2(string):\n",
    "    return \"_thread2_\" in string\n",
    "def _4(string):\n",
    "    return \"_thread4_\" in string\n",
    "def _8(string):\n",
    "    return \"_thread8_\" in string\n",
    "\n",
    "csv = \"gpt2_test_input_thraed_aggregation.csv\"\n",
    "\n",
    "#option Threads : 1 (default : 4)\n",
    "#option Threads : 1 (default : same Threads)\n",
    "#option Threads : 1 (default : same Threads)\n",
    "#option Threads : 1 (default : same Threads)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_1)]\n",
    "name_option = \"Threads 1\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option Threads : 2 (default : 4)\n",
    "#option Threads : 2 (default : same Threads)\n",
    "#option Threads : 2 (default : same Threads)\n",
    "#option Threads : 2 (default : same Threads)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_2)]\n",
    "name_option = \"Threads 2\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option Threads : 4 (default : 4)\n",
    "#option Threads : 4 (default : same Threads)\n",
    "#option Threads : 4 (default : same Threads)\n",
    "#option Threads : 4 (default : same Threads)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin4')[pd.read_csv(csv, sep=';', encoding='latin4')['name_'].apply(_4)]\n",
    "name_option = \"Threads 4\"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option Threads : 8 (default : 4)\n",
    "#option Threads : 8 (default : same Threads)\n",
    "#option Threads : 8 (default : same Threads)\n",
    "#option Threads : 8 (default : same Threads)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin8')[pd.read_csv(csv, sep=';', encoding='latin8')['name_'].apply(_8)]\n",
    "name_option = \"Threads 8\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88542574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_top-k_aggregation.csv\n",
    "def _5(string):\n",
    "    return \"_5_\" in string\n",
    "def _20(string):\n",
    "    return \"_20_\" in string\n",
    "def _100(string):\n",
    "    return \"_100_\" in string\n",
    "\n",
    "\n",
    "csv=\"gpt2_test_input_top-k_aggregation.csv\"\n",
    "\n",
    "#option top-k sampling : 5 (default : 40)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_5)]\n",
    "name_option = \"top-k : 5 \"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option top-k sampling : 20 (default : 40)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_20)]\n",
    "name_option = \"top-k : 20 \"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option top-k sampling : 100 (default : 40)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_100)]\n",
    "name_option = \"top-k : 100 \"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e65b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_top-p_aggregation.csv\n",
    "def _01(string):\n",
    "    return \"_01_\" in string\n",
    "def _05(string):\n",
    "    return \"_05_\" in string\n",
    "def _99(string):\n",
    "    return \"_99_\" in string\n",
    "\n",
    "\n",
    "csv=\"gpt2_test_input_top-p_aggregation.csv\"\n",
    "\n",
    "#option top-k sampling : 0.1 (default : 40)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_01)]\n",
    "name_option = \"top-p : 5 \"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option top-k sampling : 0.5 (default : 40)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_05)]\n",
    "name_option = \"top-p : 20 \"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option top-k sampling : 0.99 (default : 40)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_99)]\n",
    "name_option = \"top-k : 100 \"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "877eb7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_typical_aggregation.csv\n",
    "def _0(string):\n",
    "    return \"_0_\" in string\n",
    "def _5(string):\n",
    "    return \"_5_\" in string\n",
    "def _9(string):\n",
    "    return \"_9_\" in string\n",
    "\n",
    "\n",
    "csv=\"gpt2_test_input_typical_aggregation.csv\"\n",
    "\n",
    "#option locally typical sampling: 0 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_0)]\n",
    "name_option = \"typicaly : 0 \"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option locally typical sampling: 5 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_5)]\n",
    "name_option = \"typicaly : 5 \"\n",
    "preparation_data(df,name_option)\n",
    "\n",
    "#option locally typical sampling: 9 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')[pd.read_csv(csv, sep=';', encoding='latin1')['name_'].apply(_9)]\n",
    "name_option = \"typicaly : 9 \"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "935be562",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88823eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Option</th>\n",
       "      <th>mean_load_time</th>\n",
       "      <th>mean_sample_token_per_seconde</th>\n",
       "      <th>mean_prompt_eval_time_token_per_seconde</th>\n",
       "      <th>mean_eval_time_token_per_seconde</th>\n",
       "      <th>mean_total_time_token_per_seconde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>without option</td>\n",
       "      <td>943.806</td>\n",
       "      <td>10216.819</td>\n",
       "      <td>19.284</td>\n",
       "      <td>3.827</td>\n",
       "      <td>4.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KV_f32</td>\n",
       "      <td>330.722</td>\n",
       "      <td>12319.718</td>\n",
       "      <td>32.130</td>\n",
       "      <td>11.391</td>\n",
       "      <td>12.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KV_f16</td>\n",
       "      <td>313.495</td>\n",
       "      <td>12124.155</td>\n",
       "      <td>35.558</td>\n",
       "      <td>12.617</td>\n",
       "      <td>14.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grp_att_factor_2</td>\n",
       "      <td>165.125</td>\n",
       "      <td>12501.543</td>\n",
       "      <td>35.580</td>\n",
       "      <td>13.423</td>\n",
       "      <td>14.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>grp_att_width_256</td>\n",
       "      <td>302.728</td>\n",
       "      <td>12501.669</td>\n",
       "      <td>37.633</td>\n",
       "      <td>14.262</td>\n",
       "      <td>15.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>top-p : 20</td>\n",
       "      <td>508.335</td>\n",
       "      <td>12253.822</td>\n",
       "      <td>31.408</td>\n",
       "      <td>11.621</td>\n",
       "      <td>12.724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>top-k : 100</td>\n",
       "      <td>424.816</td>\n",
       "      <td>12116.249</td>\n",
       "      <td>29.658</td>\n",
       "      <td>13.351</td>\n",
       "      <td>14.357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>typicaly : 0</td>\n",
       "      <td>661.316</td>\n",
       "      <td>11811.744</td>\n",
       "      <td>35.932</td>\n",
       "      <td>14.107</td>\n",
       "      <td>16.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>typicaly : 5</td>\n",
       "      <td>308.366</td>\n",
       "      <td>11734.240</td>\n",
       "      <td>31.768</td>\n",
       "      <td>17.026</td>\n",
       "      <td>18.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>typicaly : 9</td>\n",
       "      <td>141.671</td>\n",
       "      <td>11500.199</td>\n",
       "      <td>47.402</td>\n",
       "      <td>17.190</td>\n",
       "      <td>18.939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Option  mean_load_time  mean_sample_token_per_seconde  \\\n",
       "0      without option         943.806                      10216.819   \n",
       "1              KV_f32         330.722                      12319.718   \n",
       "2              KV_f16         313.495                      12124.155   \n",
       "3    grp_att_factor_2         165.125                      12501.543   \n",
       "4   grp_att_width_256         302.728                      12501.669   \n",
       "..                ...             ...                            ...   \n",
       "89        top-p : 20          508.335                      12253.822   \n",
       "90       top-k : 100          424.816                      12116.249   \n",
       "91      typicaly : 0          661.316                      11811.744   \n",
       "92      typicaly : 5          308.366                      11734.240   \n",
       "93      typicaly : 9          141.671                      11500.199   \n",
       "\n",
       "    mean_prompt_eval_time_token_per_seconde  mean_eval_time_token_per_seconde  \\\n",
       "0                                    19.284                             3.827   \n",
       "1                                    32.130                            11.391   \n",
       "2                                    35.558                            12.617   \n",
       "3                                    35.580                            13.423   \n",
       "4                                    37.633                            14.262   \n",
       "..                                      ...                               ...   \n",
       "89                                   31.408                            11.621   \n",
       "90                                   29.658                            13.351   \n",
       "91                                   35.932                            14.107   \n",
       "92                                   31.768                            17.026   \n",
       "93                                   47.402                            17.190   \n",
       "\n",
       "    mean_total_time_token_per_seconde  \n",
       "0                               4.454  \n",
       "1                              12.766  \n",
       "2                              14.311  \n",
       "3                              14.930  \n",
       "4                              15.816  \n",
       "..                                ...  \n",
       "89                             12.724  \n",
       "90                             14.357  \n",
       "91                             16.039  \n",
       "92                             18.205  \n",
       "93                             18.939  \n",
       "\n",
       "[94 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d497de",
   "metadata": {},
   "source": [
    "## 4) Load_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f86e122",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_load_time = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_load_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dfa0d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typicaly : 9      with a mean time of   141.671  ms\n",
      "Threads 4     with a mean time of   155.05  ms\n",
      "grp_att_factor_2     with a mean time of   165.125  ms\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   171.038  ms\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   173.982  ms\n",
      "Threads 2     with a mean time of   181.132  ms\n",
      "min-p 0.1     with a mean time of   182.367  ms\n",
      "_np01_ns1_ps10     with a mean time of   213.979  ms\n",
      "min-p 0.3     with a mean time of   222.327  ms\n",
      "Threads 1     with a mean time of   225.786  ms\n",
      "_np05_ns2_ps1_     with a mean time of   245.314  ms\n",
      "_np05_ns2_ps10_     with a mean time of   261.988  ms\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   284.98  ms\n",
      "min-p 0.01     with a mean time of   289.35  ms\n",
      "grp_att_width_256     with a mean time of   302.728  ms\n",
      "_np09_ns10_ps1_     with a mean time of   303.838  ms\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   306.154  ms\n",
      "typicaly : 5      with a mean time of   308.366  ms\n",
      "top-k : 20      with a mean time of   311.689  ms\n",
      "KV_f16     with a mean time of   313.495  ms\n",
      "keep_0     with a mean time of   316.658  ms\n",
      "KV_f32     with a mean time of   330.722  ms\n",
      "_np05_ns10_ps2_     with a mean time of   340.838  ms\n",
      "temp : 5     with a mean time of   343.775  ms\n",
      "_np05_ns10_ps10_     with a mean time of   348.644  ms\n",
      "keep_all     with a mean time of   352.145  ms\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   355.112  ms\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   358.176  ms\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   358.751  ms\n",
      "_np01_ns2_ps10_     with a mean time of   360.624  ms\n",
      "temp : 0.5     with a mean time of   373.057  ms\n",
      "_np01_ns1_ps2_     with a mean time of   378.169  ms\n",
      "_np09_ns1_ps10_     with a mean time of   395.42  ms\n",
      "grp_att_factor_width     with a mean time of   396.443  ms\n",
      "repeat last n : 0     with a mean time of   398.63  ms\n",
      "_np05_ns2_ps2_     with a mean time of   416.402  ms\n",
      "top-k : 100      with a mean time of   421.154  ms\n",
      "top-k : 100      with a mean time of   424.816  ms\n",
      "_np09_ns1_ps2_     with a mean time of   441.8  ms\n",
      "_np09_ns10_ps2_     with a mean time of   442.618  ms\n",
      "_np05_ns1_ps2_     with a mean time of   447.989  ms\n",
      "repeat last n : 32     with a mean time of   455.15  ms\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   455.29  ms\n",
      "temp : 0     with a mean time of   459.572  ms\n",
      "_np05_ns1_ps10_     with a mean time of   469.323  ms\n",
      "_np01_ns1_ps1_     with a mean time of   479.632  ms\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   499.395  ms\n",
      "top-p : 20      with a mean time of   508.335  ms\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   515.82  ms\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   548.236  ms\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   558.721  ms\n",
      "_np05_ns10_ps1_     with a mean time of   579.31  ms\n",
      "_np09_ns2_ps2     with a mean time of   601.264  ms\n",
      "top-p : 5      with a mean time of   627.645  ms\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   630.363  ms\n",
      "tfs : 0.95     with a mean time of   645.315  ms\n",
      "top-k : 5      with a mean time of   652.963  ms\n",
      "typicaly : 0      with a mean time of   661.316  ms\n",
      "_np01_ns2_ps1_     with a mean time of   663.796  ms\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   671.264  ms\n",
      "_np09_ns10_ps10     with a mean time of   686.066  ms\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   705.332  ms\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   714.92  ms\n",
      "_np09_ns2_ps1     with a mean time of   725.43  ms\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   739.786  ms\n",
      "repeat last n : 128     with a mean time of   749.002  ms\n",
      "_np01_ns10_ps1_     with a mean time of   755.954  ms\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   769.693  ms\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   829.874  ms\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   854.973  ms\n",
      "repeat last n : context file     with a mean time of   883.41  ms\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   893.768  ms\n",
      "_np09_ns2_ps10_     with a mean time of   910.156  ms\n",
      "tfs : 0.6     with a mean time of   916.909  ms\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   921.38  ms\n",
      "_np01_ns10_ps10_     with a mean time of   932.942  ms\n",
      "without option     with a mean time of   943.806  ms\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   954.005  ms\n",
      "keep_20     with a mean time of   969.951  ms\n",
      "_np01_ns2_ps2_     with a mean time of   1000.029  ms\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   1031.747  ms\n",
      "repeat penalty : 1.5     with a mean time of   1041.071  ms\n",
      "tfs : 0.9     with a mean time of   1054.57  ms\n",
      "_np01_ns10_ps2_     with a mean time of   1091.154  ms\n",
      "_np09_ns1_ps1_     with a mean time of   1126.672  ms\n",
      "repeat penalty : 1     with a mean time of   1128.306  ms\n",
      "tfs : 0.1     with a mean time of   1143.974  ms\n",
      "Normal     with a mean time of   1177.462  ms\n",
      "repeat penalty n : 20     with a mean time of   1256.362  ms\n",
      "_np05_ns1_ps1_     with a mean time of   1322.203  ms\n",
      "tfs : 0.8     with a mean time of   1527.043  ms\n",
      "disable KV offload     with a mean time of   1667.511  ms\n",
      "tfs : 1 disabled     with a mean time of   2133.333  ms\n",
      "Threads 8     with a mean time of   65320.1  ms\n"
     ]
    }
   ],
   "source": [
    "df_load_timedf_sorted = df_load_time.sort_values(by='mean_load_time')\n",
    "for i in range(len(df_load_timedf_sorted)):\n",
    "    print(df_load_timedf_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_load_timedf_sorted.iloc[i,1]) + \"  ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a0e84",
   "metadata": {},
   "source": [
    "## 5) sample token per sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2dc09ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_sample = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_sample_token_per_seconde']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "347342c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-k : 5      with a mean time of   14635.826  tokens per seconde\n",
      "Threads 1     with a mean time of   13850.154  tokens per seconde\n",
      "top-k : 20      with a mean time of   13011.292  tokens per seconde\n",
      "top-p : 5      with a mean time of   12938.256  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   12868.266  tokens per seconde\n",
      "Threads 4     with a mean time of   12597.441  tokens per seconde\n",
      "Threads 2     with a mean time of   12557.622  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   12501.669  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   12501.543  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   12481.903  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   12474.818  tokens per seconde\n",
      "KV_f32     with a mean time of   12319.718  tokens per seconde\n",
      "top-p : 20      with a mean time of   12253.822  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   12133.858  tokens per seconde\n",
      "KV_f16     with a mean time of   12124.155  tokens per seconde\n",
      "top-k : 100      with a mean time of   12116.249  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   11968.294  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11929.263  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   11865.264  tokens per seconde\n",
      "typicaly : 0      with a mean time of   11811.744  tokens per seconde\n",
      "typicaly : 5      with a mean time of   11734.24  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   11733.776  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   11732.757  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   11725.377  tokens per seconde\n",
      "keep_0     with a mean time of   11689.775  tokens per seconde\n",
      "min-p 0.1     with a mean time of   11539.755  tokens per seconde\n",
      "keep_all     with a mean time of   11523.565  tokens per seconde\n",
      "typicaly : 9      with a mean time of   11500.199  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   11487.854  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   11362.083  tokens per seconde\n",
      "temp : 0.5     with a mean time of   11257.88  tokens per seconde\n",
      "temp : 5     with a mean time of   11248.203  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   11218.808  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   11142.144  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   11128.915  tokens per seconde\n",
      "min-p 0.01     with a mean time of   11115.159  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   11078.447  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   11001.165  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   10858.744  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   10798.043  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   10796.221  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   10693.329  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   10669.0  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   10575.269  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   10541.839  tokens per seconde\n",
      "Threads 8     with a mean time of   10532.84  tokens per seconde\n",
      "disable KV offload     with a mean time of   10516.053  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   10503.113  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   10326.419  tokens per seconde\n",
      "without option     with a mean time of   10216.819  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   10144.506  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   9989.345  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   9888.492  tokens per seconde\n",
      "min-p 0.3     with a mean time of   9857.399  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   9616.406  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   9603.436  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   9550.504  tokens per seconde\n",
      "top-k : 100      with a mean time of   9549.133  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   9510.503  tokens per seconde\n",
      "Normal     with a mean time of   9444.462  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   9376.343  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   9333.044  tokens per seconde\n",
      "keep_20     with a mean time of   9250.937  tokens per seconde\n",
      "tfs : 0.6     with a mean time of   9242.416  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   9078.555  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   8840.493  tokens per seconde\n",
      "temp : 0     with a mean time of   8323.807  tokens per seconde\n",
      "tfs : 0.8     with a mean time of   8083.662  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   903.9  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   842.557  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   120.991  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   120.876  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   117.741  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   108.194  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   102.392  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   99.732  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   98.879  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   96.911  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   94.692  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   94.612  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   94.587  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   90.078  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   70.525  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   69.437  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   69.371  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   69.147  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   68.832  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   68.052  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   67.262  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   57.465  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   53.376  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   49.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   48.5  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   45.586  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "df_sample_sorted = df_sample.sort_values(by='mean_sample_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_sample_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_sample_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26d1fc",
   "metadata": {},
   "source": [
    "## 6) mean_prompt_eval_time_token_per_seconde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5ce3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_prompt_eval = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_prompt_eval_time_token_per_seconde']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edd8c0c3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top-k : 5      with a mean time of   14635.826  tokens per seconde\n",
      "Threads 1     with a mean time of   13850.154  tokens per seconde\n",
      "top-k : 20      with a mean time of   13011.292  tokens per seconde\n",
      "top-p : 5      with a mean time of   12938.256  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   12868.266  tokens per seconde\n",
      "Threads 4     with a mean time of   12597.441  tokens per seconde\n",
      "Threads 2     with a mean time of   12557.622  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   12501.669  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   12501.543  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   12481.903  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   12474.818  tokens per seconde\n",
      "KV_f32     with a mean time of   12319.718  tokens per seconde\n",
      "top-p : 20      with a mean time of   12253.822  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   12133.858  tokens per seconde\n",
      "KV_f16     with a mean time of   12124.155  tokens per seconde\n",
      "top-k : 100      with a mean time of   12116.249  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   11968.294  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11929.263  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   11865.264  tokens per seconde\n",
      "typicaly : 0      with a mean time of   11811.744  tokens per seconde\n",
      "typicaly : 5      with a mean time of   11734.24  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   11733.776  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   11732.757  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   11725.377  tokens per seconde\n",
      "keep_0     with a mean time of   11689.775  tokens per seconde\n",
      "min-p 0.1     with a mean time of   11539.755  tokens per seconde\n",
      "keep_all     with a mean time of   11523.565  tokens per seconde\n",
      "typicaly : 9      with a mean time of   11500.199  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   11487.854  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   11362.083  tokens per seconde\n",
      "temp : 0.5     with a mean time of   11257.88  tokens per seconde\n",
      "temp : 5     with a mean time of   11248.203  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   11218.808  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   11142.144  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   11128.915  tokens per seconde\n",
      "min-p 0.01     with a mean time of   11115.159  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   11078.447  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   11001.165  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   10858.744  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   10798.043  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   10796.221  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   10693.329  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   10669.0  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   10575.269  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   10541.839  tokens per seconde\n",
      "Threads 8     with a mean time of   10532.84  tokens per seconde\n",
      "disable KV offload     with a mean time of   10516.053  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   10503.113  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   10326.419  tokens per seconde\n",
      "without option     with a mean time of   10216.819  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   10144.506  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   9989.345  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   9888.492  tokens per seconde\n",
      "min-p 0.3     with a mean time of   9857.399  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   9616.406  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   9603.436  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   9550.504  tokens per seconde\n",
      "top-k : 100      with a mean time of   9549.133  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   9510.503  tokens per seconde\n",
      "Normal     with a mean time of   9444.462  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   9376.343  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   9333.044  tokens per seconde\n",
      "keep_20     with a mean time of   9250.937  tokens per seconde\n",
      "tfs : 0.6     with a mean time of   9242.416  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   9078.555  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   8840.493  tokens per seconde\n",
      "temp : 0     with a mean time of   8323.807  tokens per seconde\n",
      "tfs : 0.8     with a mean time of   8083.662  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   903.9  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   842.557  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   120.991  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   120.876  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   117.741  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   108.194  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   102.392  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   99.732  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   98.879  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   96.911  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   94.692  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   94.612  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   94.587  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   90.078  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   70.525  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   69.437  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   69.371  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   69.147  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   68.832  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   68.052  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   67.262  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   57.465  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   53.376  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   49.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   48.5  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   45.586  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "df_prompt_eval_sorted = df_prompt_eval.sort_values(by='mean_prompt_eval_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_sample_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_sample_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6329280",
   "metadata": {},
   "source": [
    "## 7) mean_eval_time_token_per_seconde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9c9859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_eval = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_eval_time_token_per_seconde']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f42da9a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads 2     with a mean time of   25.434  tokens per seconde\n",
      "Threads 1     with a mean time of   20.29  tokens per seconde\n",
      "typicaly : 9      with a mean time of   17.19  tokens per seconde\n",
      "typicaly : 5      with a mean time of   17.026  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   15.691  tokens per seconde\n",
      "Threads 4     with a mean time of   14.777  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   14.262  tokens per seconde\n",
      "typicaly : 0      with a mean time of   14.107  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   13.596  tokens per seconde\n",
      "top-p : 5      with a mean time of   13.569  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   13.423  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.351  tokens per seconde\n",
      "KV_f16     with a mean time of   12.617  tokens per seconde\n",
      "top-k : 100      with a mean time of   12.544  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   11.882  tokens per seconde\n",
      "top-p : 20      with a mean time of   11.621  tokens per seconde\n",
      "KV_f32     with a mean time of   11.391  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   10.944  tokens per seconde\n",
      "keep_all     with a mean time of   10.114  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   9.994  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   9.873  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   9.592  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.437  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   9.345  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   9.201  tokens per seconde\n",
      "top-k : 5      with a mean time of   9.097  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.064  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   8.991  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   8.977  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.952  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.684  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.68  tokens per seconde\n",
      "temp : 0     with a mean time of   8.585  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   8.37  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   8.351  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   8.305  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   8.134  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   8.053  tokens per seconde\n",
      "keep_0     with a mean time of   7.986  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   7.945  tokens per seconde\n",
      "top-k : 20      with a mean time of   7.911  tokens per seconde\n",
      "min-p 0.01     with a mean time of   7.911  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   7.898  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   7.729  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   7.643  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   7.615  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   7.541  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.54  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   7.51  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   7.451  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.192  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   7.183  tokens per seconde\n",
      "min-p 0.1     with a mean time of   7.148  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.127  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.009  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   6.977  tokens per seconde\n",
      "temp : 0.5     with a mean time of   6.762  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.664  tokens per seconde\n",
      "temp : 5     with a mean time of   6.622  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   6.446  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   6.428  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   6.345  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   6.296  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.263  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   6.088  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   5.964  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   5.92  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   5.8  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   5.799  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   5.772  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   5.722  tokens per seconde\n",
      "keep_20     with a mean time of   5.098  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   5.075  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.01  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   4.993  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   4.959  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   4.641  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   4.615  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   4.536  tokens per seconde\n",
      "disable KV offload     with a mean time of   4.479  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   4.444  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   4.378  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   4.357  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.354  tokens per seconde\n",
      "Normal     with a mean time of   4.06  tokens per seconde\n",
      "without option     with a mean time of   3.827  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   3.714  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.324  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.14  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   2.894  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   2.836  tokens per seconde\n",
      "tfs : 0.6     with a mean time of   2.168  tokens per seconde\n",
      "tfs : 0.8     with a mean time of   1.972  tokens per seconde\n",
      "Threads 8     with a mean time of   0.01  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "df_eval_sorted = df_eval.sort_values(by='mean_eval_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_eval_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_eval_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e010cce",
   "metadata": {},
   "source": [
    "## 8) mean_total_time_token_per_seconde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e9806a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_total = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_total_time_token_per_seconde']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79c75b84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threads 2     with a mean time of   27.175  tokens per seconde\n",
      "Threads 1     with a mean time of   21.524  tokens per seconde\n",
      "typicaly : 9      with a mean time of   18.939  tokens per seconde\n",
      "typicaly : 5      with a mean time of   18.205  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   17.002  tokens per seconde\n",
      "typicaly : 0      with a mean time of   16.039  tokens per seconde\n",
      "Threads 4     with a mean time of   15.965  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   15.816  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   14.963  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   14.93  tokens per seconde\n",
      "top-p : 5      with a mean time of   14.807  tokens per seconde\n",
      "top-k : 100      with a mean time of   14.357  tokens per seconde\n",
      "KV_f16     with a mean time of   14.311  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.679  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   13.253  tokens per seconde\n",
      "KV_f32     with a mean time of   12.766  tokens per seconde\n",
      "top-p : 20      with a mean time of   12.724  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   12.143  tokens per seconde\n",
      "keep_all     with a mean time of   11.318  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11.279  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   10.537  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   10.477  tokens per seconde\n",
      "top-k : 5      with a mean time of   10.304  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   10.293  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   10.254  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   10.22  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   10.195  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   9.67  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.529  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   9.512  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.494  tokens per seconde\n",
      "temp : 0     with a mean time of   9.493  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   9.343  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   9.262  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   9.126  tokens per seconde\n",
      "top-k : 20      with a mean time of   9.098  tokens per seconde\n",
      "min-p 0.01     with a mean time of   9.084  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   9.07  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   9.022  tokens per seconde\n",
      "keep_0     with a mean time of   8.96  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   8.954  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   8.913  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.552  tokens per seconde\n",
      "min-p 0.1     with a mean time of   8.365  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   8.35  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   8.238  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.229  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.133  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   8.035  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.03  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.012  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.826  tokens per seconde\n",
      "temp : 0.5     with a mean time of   7.759  tokens per seconde\n",
      "temp : 5     with a mean time of   7.749  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.695  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.672  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   7.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.493  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.457  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   7.268  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   7.214  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   7.149  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   7.091  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   7.075  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.074  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.918  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   6.633  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   6.603  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.559  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   6.545  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   6.375  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   6.027  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.944  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   5.93  tokens per seconde\n",
      "keep_20     with a mean time of   5.846  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   5.838  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   5.419  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   5.412  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   5.388  tokens per seconde\n",
      "disable KV offload     with a mean time of   5.313  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   5.268  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   5.142  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   5.108  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.976  tokens per seconde\n",
      "Normal     with a mean time of   4.734  tokens per seconde\n",
      "without option     with a mean time of   4.454  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   4.424  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.913  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.742  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   3.418  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   3.415  tokens per seconde\n",
      "tfs : 0.6     with a mean time of   2.607  tokens per seconde\n",
      "tfs : 0.8     with a mean time of   2.401  tokens per seconde\n",
      "Threads 8     with a mean time of   0.035  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "df_total_sorted = df_total.sort_values(by='mean_total_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_total_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_total_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abb4c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9134cccd",
   "metadata": {},
   "source": [
    "## Try new commandes and options "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80a4134",
   "metadata": {},
   "source": [
    "### Try1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e6361",
   "metadata": {},
   "source": [
    " ``` ../llama.cpp/main.exe -m \"$model\" -s 987654321 --file \"$input_file\" -n 100 -t 2 --typical 0.9 -np 0.5 -ns 2 -ps 1 -gaw 256 --top-p 5 -ctk f16 -ctv f16 --top-k 100 --repeat_last_n 32 --temp 0 --tfs 0.95 > \"$output_res_file\" 2> \"$output_log_file\" ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c627bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_typical_aggregation.csv\n",
    "\n",
    "csv=\"gpt2_test_input_try1_aggregation.csv\"\n",
    "\n",
    "#option locally typical sampling: 0 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "name_option = \"try1 \"\n",
    "preparation_data(df,name_option)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "236c3540",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try1      with a mean time of   29.265  tokens per seconde\n",
      "Threads 2     with a mean time of   27.175  tokens per seconde\n",
      "Threads 1     with a mean time of   21.524  tokens per seconde\n",
      "typicaly : 9      with a mean time of   18.939  tokens per seconde\n",
      "typicaly : 5      with a mean time of   18.205  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   17.002  tokens per seconde\n",
      "typicaly : 0      with a mean time of   16.039  tokens per seconde\n",
      "Threads 4     with a mean time of   15.965  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   15.816  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   14.963  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   14.93  tokens per seconde\n",
      "top-p : 5      with a mean time of   14.807  tokens per seconde\n",
      "top-k : 100      with a mean time of   14.357  tokens per seconde\n",
      "KV_f16     with a mean time of   14.311  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.679  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   13.253  tokens per seconde\n",
      "KV_f32     with a mean time of   12.766  tokens per seconde\n",
      "top-p : 20      with a mean time of   12.724  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   12.143  tokens per seconde\n",
      "keep_all     with a mean time of   11.318  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11.279  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   10.537  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   10.477  tokens per seconde\n",
      "top-k : 5      with a mean time of   10.304  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   10.293  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   10.254  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   10.22  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   10.195  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   9.67  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.529  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   9.512  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.494  tokens per seconde\n",
      "temp : 0     with a mean time of   9.493  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   9.343  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   9.262  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   9.126  tokens per seconde\n",
      "top-k : 20      with a mean time of   9.098  tokens per seconde\n",
      "min-p 0.01     with a mean time of   9.084  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   9.07  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   9.022  tokens per seconde\n",
      "keep_0     with a mean time of   8.96  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   8.954  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   8.913  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.552  tokens per seconde\n",
      "min-p 0.1     with a mean time of   8.365  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   8.35  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   8.238  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.229  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.133  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   8.035  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.03  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.012  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.826  tokens per seconde\n",
      "temp : 0.5     with a mean time of   7.759  tokens per seconde\n",
      "temp : 5     with a mean time of   7.749  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.695  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.672  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   7.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.493  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.457  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   7.268  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   7.214  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   7.149  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   7.091  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   7.075  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.074  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.918  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   6.633  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   6.603  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.559  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   6.545  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   6.375  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   6.027  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.944  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   5.93  tokens per seconde\n",
      "keep_20     with a mean time of   5.846  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   5.838  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   5.419  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   5.412  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   5.388  tokens per seconde\n",
      "disable KV offload     with a mean time of   5.313  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   5.268  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   5.142  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   5.108  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.976  tokens per seconde\n",
      "Normal     with a mean time of   4.734  tokens per seconde\n",
      "without option     with a mean time of   4.454  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   4.424  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.913  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.742  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   3.418  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   3.415  tokens per seconde\n",
      "tfs : 0.6     with a mean time of   2.607  tokens per seconde\n",
      "tfs : 0.8     with a mean time of   2.401  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_total = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_total_time_token_per_seconde']]\n",
    "df_total_sorted = df_total.sort_values(by='mean_total_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_total_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_total_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871f111",
   "metadata": {},
   "source": [
    "### Try2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c09f0a4",
   "metadata": {},
   "source": [
    "```../llama.cpp/main.exe -m \"$model\" -s 987654321 --file \"$input_file\" -n 100 -t 2 --typical 0.9 -np 0.5 -ns 2 -ps 1 -gaw 256 --top-p 5 -ctk f16 -ctv f16 --top-k 100 --repeat_last_n 32 > \"$output_res_file\" 2> \"$output_log_file\"```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb174f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_typical_aggregation.csv\n",
    "\n",
    "csv=\"gpt2_test_input_try2_aggregation.csv\"\n",
    "\n",
    "#option locally typical sampling: 0 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "name_option = \"try2 \"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bc4444d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try1      with a mean time of   29.265  tokens per seconde\n",
      "try2      with a mean time of   28.525  tokens per seconde\n",
      "Threads 2     with a mean time of   27.175  tokens per seconde\n",
      "Threads 1     with a mean time of   21.524  tokens per seconde\n",
      "typicaly : 9      with a mean time of   18.939  tokens per seconde\n",
      "typicaly : 5      with a mean time of   18.205  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   17.002  tokens per seconde\n",
      "typicaly : 0      with a mean time of   16.039  tokens per seconde\n",
      "Threads 4     with a mean time of   15.965  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   15.816  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   14.963  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   14.93  tokens per seconde\n",
      "top-p : 5      with a mean time of   14.807  tokens per seconde\n",
      "top-k : 100      with a mean time of   14.357  tokens per seconde\n",
      "KV_f16     with a mean time of   14.311  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.679  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   13.253  tokens per seconde\n",
      "KV_f32     with a mean time of   12.766  tokens per seconde\n",
      "top-p : 20      with a mean time of   12.724  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   12.143  tokens per seconde\n",
      "keep_all     with a mean time of   11.318  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11.279  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   10.537  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   10.477  tokens per seconde\n",
      "top-k : 5      with a mean time of   10.304  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   10.293  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   10.254  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   10.22  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   10.195  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   9.67  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.529  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   9.512  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.494  tokens per seconde\n",
      "temp : 0     with a mean time of   9.493  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   9.343  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   9.262  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   9.126  tokens per seconde\n",
      "top-k : 20      with a mean time of   9.098  tokens per seconde\n",
      "min-p 0.01     with a mean time of   9.084  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   9.07  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   9.022  tokens per seconde\n",
      "keep_0     with a mean time of   8.96  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   8.954  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   8.913  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.552  tokens per seconde\n",
      "min-p 0.1     with a mean time of   8.365  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   8.35  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   8.238  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.229  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.133  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   8.035  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.03  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.012  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.826  tokens per seconde\n",
      "temp : 0.5     with a mean time of   7.759  tokens per seconde\n",
      "temp : 5     with a mean time of   7.749  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.695  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.672  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   7.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.493  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.457  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   7.268  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   7.214  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   7.149  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   7.091  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   7.075  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.074  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.918  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   6.633  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   6.603  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.559  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   6.545  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   6.375  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   6.027  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.944  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   5.93  tokens per seconde\n",
      "keep_20     with a mean time of   5.846  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   5.838  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   5.419  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   5.412  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   5.388  tokens per seconde\n",
      "disable KV offload     with a mean time of   5.313  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   5.268  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   5.142  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   5.108  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.976  tokens per seconde\n",
      "Normal     with a mean time of   4.734  tokens per seconde\n",
      "without option     with a mean time of   4.454  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   4.424  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.913  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.742  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   3.418  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   3.415  tokens per seconde\n",
      "tfs : 0.6     with a mean time of   2.607  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_total = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_total_time_token_per_seconde']]\n",
    "df_total_sorted = df_total.sort_values(by='mean_total_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_total_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_total_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9b1a52",
   "metadata": {},
   "source": [
    "### Try3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0788af",
   "metadata": {},
   "source": [
    "``` \n",
    "../llama.cpp/main.exe -m \"$model\" -s 987654321 --file \"$input_file\" -n 100 -t 2 --typical 0.9 -gaw 256 --top-p 5 -ctk f16 -ctv f16 --top-k 100 --repeat_last_n 32 > \"$output_res_file\" 2> \"$output_log_file\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "845eb549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_typical_aggregation.csv\n",
    "\n",
    "csv=\"gpt2_test_input_try3_aggregation.csv\"\n",
    "\n",
    "#option locally typical sampling: 0 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "name_option = \"try3 \"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e583faa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try1      with a mean time of   29.265  tokens per seconde\n",
      "try3      with a mean time of   28.999  tokens per seconde\n",
      "try2      with a mean time of   28.525  tokens per seconde\n",
      "Threads 2     with a mean time of   27.175  tokens per seconde\n",
      "Threads 1     with a mean time of   21.524  tokens per seconde\n",
      "typicaly : 9      with a mean time of   18.939  tokens per seconde\n",
      "typicaly : 5      with a mean time of   18.205  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   17.002  tokens per seconde\n",
      "typicaly : 0      with a mean time of   16.039  tokens per seconde\n",
      "Threads 4     with a mean time of   15.965  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   15.816  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   14.963  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   14.93  tokens per seconde\n",
      "top-p : 5      with a mean time of   14.807  tokens per seconde\n",
      "top-k : 100      with a mean time of   14.357  tokens per seconde\n",
      "KV_f16     with a mean time of   14.311  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.679  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   13.253  tokens per seconde\n",
      "KV_f32     with a mean time of   12.766  tokens per seconde\n",
      "top-p : 20      with a mean time of   12.724  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   12.143  tokens per seconde\n",
      "keep_all     with a mean time of   11.318  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11.279  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   10.537  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   10.477  tokens per seconde\n",
      "top-k : 5      with a mean time of   10.304  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   10.293  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   10.254  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   10.22  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   10.195  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   9.67  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.529  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   9.512  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.494  tokens per seconde\n",
      "temp : 0     with a mean time of   9.493  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   9.343  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   9.262  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   9.126  tokens per seconde\n",
      "top-k : 20      with a mean time of   9.098  tokens per seconde\n",
      "min-p 0.01     with a mean time of   9.084  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   9.07  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   9.022  tokens per seconde\n",
      "keep_0     with a mean time of   8.96  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   8.954  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   8.913  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.552  tokens per seconde\n",
      "min-p 0.1     with a mean time of   8.365  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   8.35  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   8.238  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.229  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.133  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   8.035  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.03  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.012  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.826  tokens per seconde\n",
      "temp : 0.5     with a mean time of   7.759  tokens per seconde\n",
      "temp : 5     with a mean time of   7.749  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.695  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.672  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   7.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.493  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.457  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   7.268  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   7.214  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   7.149  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   7.091  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   7.075  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.074  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.918  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   6.633  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   6.603  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.559  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   6.545  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   6.375  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   6.027  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.944  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   5.93  tokens per seconde\n",
      "keep_20     with a mean time of   5.846  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   5.838  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   5.419  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   5.412  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   5.388  tokens per seconde\n",
      "disable KV offload     with a mean time of   5.313  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   5.268  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   5.142  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   5.108  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.976  tokens per seconde\n",
      "Normal     with a mean time of   4.734  tokens per seconde\n",
      "without option     with a mean time of   4.454  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   4.424  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.913  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.742  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   3.418  tokens per seconde\n",
      "tfs : 0.9     with a mean time of   3.415  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_total = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_total_time_token_per_seconde']]\n",
    "df_total_sorted = df_total.sort_values(by='mean_total_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_total_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_total_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416dfcff",
   "metadata": {},
   "source": [
    "### Try 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de84745",
   "metadata": {},
   "source": [
    "```\n",
    "../llama.cpp/main.exe -m \"$model\" -s 987654321 --file \"$input_file\" -n 100 -t 2 --typical 0.9  --repeat_last_n 32 > \"$output_res_file\" 2> \"$output_log_file\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80a8bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_typical_aggregation.csv\n",
    "\n",
    "csv=\"gpt2_test_input_try4_aggregation.csv\"\n",
    "\n",
    "#option locally typical sampling: 0 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "name_option = \"try4 \"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "edc2014c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try1      with a mean time of   29.265  tokens per seconde\n",
      "try3      with a mean time of   28.999  tokens per seconde\n",
      "try2      with a mean time of   28.525  tokens per seconde\n",
      "try4      with a mean time of   28.016  tokens per seconde\n",
      "Threads 2     with a mean time of   27.175  tokens per seconde\n",
      "Threads 1     with a mean time of   21.524  tokens per seconde\n",
      "typicaly : 9      with a mean time of   18.939  tokens per seconde\n",
      "typicaly : 5      with a mean time of   18.205  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   17.002  tokens per seconde\n",
      "typicaly : 0      with a mean time of   16.039  tokens per seconde\n",
      "Threads 4     with a mean time of   15.965  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   15.816  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   14.963  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   14.93  tokens per seconde\n",
      "top-p : 5      with a mean time of   14.807  tokens per seconde\n",
      "top-k : 100      with a mean time of   14.357  tokens per seconde\n",
      "KV_f16     with a mean time of   14.311  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.679  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   13.253  tokens per seconde\n",
      "KV_f32     with a mean time of   12.766  tokens per seconde\n",
      "top-p : 20      with a mean time of   12.724  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   12.143  tokens per seconde\n",
      "keep_all     with a mean time of   11.318  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11.279  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   10.537  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   10.477  tokens per seconde\n",
      "top-k : 5      with a mean time of   10.304  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   10.293  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   10.254  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   10.22  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   10.195  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   9.67  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.529  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   9.512  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.494  tokens per seconde\n",
      "temp : 0     with a mean time of   9.493  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   9.343  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   9.262  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   9.126  tokens per seconde\n",
      "top-k : 20      with a mean time of   9.098  tokens per seconde\n",
      "min-p 0.01     with a mean time of   9.084  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   9.07  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   9.022  tokens per seconde\n",
      "keep_0     with a mean time of   8.96  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   8.954  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   8.913  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.552  tokens per seconde\n",
      "min-p 0.1     with a mean time of   8.365  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   8.35  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   8.238  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.229  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.133  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   8.035  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.03  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.012  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.826  tokens per seconde\n",
      "temp : 0.5     with a mean time of   7.759  tokens per seconde\n",
      "temp : 5     with a mean time of   7.749  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.695  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.672  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   7.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.493  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.457  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   7.268  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   7.214  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   7.149  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   7.091  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   7.075  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.074  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.918  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   6.633  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   6.603  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.559  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   6.545  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   6.375  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   6.027  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.944  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   5.93  tokens per seconde\n",
      "keep_20     with a mean time of   5.846  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   5.838  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   5.419  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   5.412  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   5.388  tokens per seconde\n",
      "disable KV offload     with a mean time of   5.313  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   5.268  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   5.142  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   5.108  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.976  tokens per seconde\n",
      "Normal     with a mean time of   4.734  tokens per seconde\n",
      "without option     with a mean time of   4.454  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   4.424  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.913  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.742  tokens per seconde\n",
      "tfs : 0.1     with a mean time of   3.418  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_total = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_total_time_token_per_seconde']]\n",
    "df_total_sorted = df_total.sort_values(by='mean_total_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_total_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_total_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef420c9",
   "metadata": {},
   "source": [
    "### Try 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b85ddb",
   "metadata": {},
   "source": [
    "```\n",
    "../llama.cpp/main.exe -m \"$model\" -s 987654321 --file \"$input_file\" -n 100 -t 2 --typical 0.9 > \"$output_res_file\" 2> \"$output_log_file\"\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6150dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preaparing data for gpt2_test_input_typical_aggregation.csv\n",
    "\n",
    "csv=\"gpt2_test_input_try5_aggregation.csv\"\n",
    "\n",
    "#option locally typical sampling: 0 (default : 1 disabled)\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "name_option = \"try5\"\n",
    "preparation_data(df,name_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5074c284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "try1      with a mean time of   29.265  tokens per seconde\n",
      "try3      with a mean time of   28.999  tokens per seconde\n",
      "try5     with a mean time of   28.862  tokens per seconde\n",
      "try2      with a mean time of   28.525  tokens per seconde\n",
      "try4      with a mean time of   28.016  tokens per seconde\n",
      "Threads 2     with a mean time of   27.175  tokens per seconde\n",
      "Threads 1     with a mean time of   21.524  tokens per seconde\n",
      "typicaly : 9      with a mean time of   18.939  tokens per seconde\n",
      "typicaly : 5      with a mean time of   18.205  tokens per seconde\n",
      "_np05_ns2_ps1_     with a mean time of   17.002  tokens per seconde\n",
      "typicaly : 0      with a mean time of   16.039  tokens per seconde\n",
      "Threads 4     with a mean time of   15.965  tokens per seconde\n",
      "grp_att_width_256     with a mean time of   15.816  tokens per seconde\n",
      "grp_att_factor_width     with a mean time of   14.963  tokens per seconde\n",
      "grp_att_factor_2     with a mean time of   14.93  tokens per seconde\n",
      "top-p : 5      with a mean time of   14.807  tokens per seconde\n",
      "top-k : 100      with a mean time of   14.357  tokens per seconde\n",
      "KV_f16     with a mean time of   14.311  tokens per seconde\n",
      "top-k : 100      with a mean time of   13.679  tokens per seconde\n",
      "repeat last n : 32     with a mean time of   13.253  tokens per seconde\n",
      "KV_f32     with a mean time of   12.766  tokens per seconde\n",
      "top-p : 20      with a mean time of   12.724  tokens per seconde\n",
      "_np05_ns1_ps10_     with a mean time of   12.143  tokens per seconde\n",
      "keep_all     with a mean time of   11.318  tokens per seconde\n",
      "_np09_ns10_ps1_     with a mean time of   11.279  tokens per seconde\n",
      "_np05_ns1_ps2_     with a mean time of   10.537  tokens per seconde\n",
      "_np01_ns1_ps2_     with a mean time of   10.477  tokens per seconde\n",
      "top-k : 5      with a mean time of   10.304  tokens per seconde\n",
      "_np01_ns1_ps10     with a mean time of   10.293  tokens per seconde\n",
      "_np05_ns10_ps2_     with a mean time of   10.254  tokens per seconde\n",
      "_np05_ns10_ps1_     with a mean time of   10.22  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   10.195  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   9.67  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   9.529  tokens per seconde\n",
      "_np09_ns1_ps10_     with a mean time of   9.512  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   9.494  tokens per seconde\n",
      "temp : 0     with a mean time of   9.493  tokens per seconde\n",
      "repeat last n : 128     with a mean time of   9.343  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   9.262  tokens per seconde\n",
      "_np09_ns10_ps10     with a mean time of   9.126  tokens per seconde\n",
      "top-k : 20      with a mean time of   9.098  tokens per seconde\n",
      "min-p 0.01     with a mean time of   9.084  tokens per seconde\n",
      "repeat last n : context file     with a mean time of   9.07  tokens per seconde\n",
      "_np09_ns2_ps1     with a mean time of   9.022  tokens per seconde\n",
      "keep_0     with a mean time of   8.96  tokens per seconde\n",
      "_np09_ns10_ps2_     with a mean time of   8.954  tokens per seconde\n",
      "repeat last n : 0     with a mean time of   8.913  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   8.552  tokens per seconde\n",
      "min-p 0.1     with a mean time of   8.365  tokens per seconde\n",
      "_np05_ns10_ps10_     with a mean time of   8.35  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   8.238  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.229  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15     with a mean time of   8.133  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 2     with a mean time of   8.035  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 5     with a mean time of   8.03  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 2     with a mean time of   8.012  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 2     with a mean time of   7.826  tokens per seconde\n",
      "temp : 0.5     with a mean time of   7.759  tokens per seconde\n",
      "temp : 5     with a mean time of   7.749  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   7.695  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.672  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   7.507  tokens per seconde\n",
      "mirostat 2 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.493  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 5     with a mean time of   7.457  tokens per seconde\n",
      "_np01_ns10_ps1_     with a mean time of   7.268  tokens per seconde\n",
      "_np01_ns2_ps10_     with a mean time of   7.214  tokens per seconde\n",
      "_np01_ns10_ps10_     with a mean time of   7.149  tokens per seconde\n",
      "_np05_ns2_ps10_     with a mean time of   7.091  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 15     with a mean time of   7.075  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 8     with a mean time of   7.074  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 5     with a mean time of   6.918  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.5 / mirostat-ent 15     with a mean time of   6.633  tokens per seconde\n",
      "_np09_ns2_ps2     with a mean time of   6.603  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.02 / mirostat-ent 8     with a mean time of   6.559  tokens per seconde\n",
      "_np01_ns10_ps2_     with a mean time of   6.545  tokens per seconde\n",
      "mirostat 1 / mirostat-lr 0.2 / mirostat-ent 8     with a mean time of   6.375  tokens per seconde\n",
      "_np05_ns2_ps2_     with a mean time of   6.027  tokens per seconde\n",
      "min-p 0.3     with a mean time of   5.944  tokens per seconde\n",
      "_np01_ns1_ps1_     with a mean time of   5.93  tokens per seconde\n",
      "keep_20     with a mean time of   5.846  tokens per seconde\n",
      "_np09_ns1_ps2_     with a mean time of   5.838  tokens per seconde\n",
      "repeat penalty : 1     with a mean time of   5.419  tokens per seconde\n",
      "repeat penalty : 1.5     with a mean time of   5.412  tokens per seconde\n",
      "_np01_ns2_ps2_     with a mean time of   5.388  tokens per seconde\n",
      "disable KV offload     with a mean time of   5.313  tokens per seconde\n",
      "tfs : 0.95     with a mean time of   5.268  tokens per seconde\n",
      "repeat penalty n : 20     with a mean time of   5.142  tokens per seconde\n",
      "_np01_ns2_ps1_     with a mean time of   5.108  tokens per seconde\n",
      "tfs : 1 disabled     with a mean time of   4.976  tokens per seconde\n",
      "Normal     with a mean time of   4.734  tokens per seconde\n",
      "without option     with a mean time of   4.454  tokens per seconde\n",
      "_np09_ns2_ps10_     with a mean time of   4.424  tokens per seconde\n",
      "_np09_ns1_ps1_     with a mean time of   3.913  tokens per seconde\n",
      "_np05_ns1_ps1_     with a mean time of   3.742  tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_total = pd.read_csv(csv, sep=';', encoding='latin1')[['Option','mean_total_time_token_per_seconde']]\n",
    "df_total_sorted = df_total.sort_values(by='mean_total_time_token_per_seconde' , ascending=False)\n",
    "for i in range(len(df_sample_sorted)):\n",
    "    print(df_total_sorted.iloc[i,0][:] + \"     with a mean time of   \" + str(df_total_sorted.iloc[i,1]) + \"  tokens per seconde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c34bbab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f8610b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c15ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ec602a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5dfb25d",
   "metadata": {},
   "source": [
    "# 1) LLAMA without options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c33d77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : GGUFV3(latest)\n",
      "mean_load_time : 943.806 ms\n",
      "mean_sample_token_per_seconde : 10216.819 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 19.284 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 3.827 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 4.454 Tokens per seconde\n"
     ]
    }
   ],
   "source": [
    "csv = \"summerize.csv\"\n",
    "df_without_option = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_without_option = df_without_option[df_without_option['Option'] == \"without option\"]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df_without_option.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df_without_option.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df_without_option.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df_without_option.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df_without_option.iloc[0,5]) + \" Tokens per seconde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ef1a113a",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = \"gpt2_test_input_only_aggregation.csv\"\n",
    "df_without_option_aggregation = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_without_option_aggregation = df_without_option_aggregation[['load_time','sample_time','ms_per_token','token_per_sec','prompt_eval_time','ms_per_token.1','token_per_sec.1','eval_time','ms_per_token.2','token_per_sec.2','total_time','name_']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd60fcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "path_input = \"../inputs/\"\n",
    "path_output = \"../outputs/gpt2_test_input_only/outputs_res/\"\n",
    "\n",
    "\n",
    "def input_output_f(df, path_output):\n",
    "    path_input = \"../inputs/\"\n",
    "    input_output = []\n",
    "    for i in range(len(df)):\n",
    "        input_tab= df.iloc[i,-1].split('_')\n",
    "\n",
    "        path_input_tmp = path_input + input_tab[0] + \".txt\"\n",
    "        path_output_tmp = path_output+ ''.join(input_tab[:-1]) + \"_res.txt\"\n",
    "\n",
    "        with open(path_input_tmp, \"r\") as f:\n",
    "            prompt = f.read()\n",
    "        with open(path_output_tmp, \"r\") as f:\n",
    "            res = f.read()\n",
    "\n",
    "        input_output.append([prompt,res])\n",
    "    return input_output\n",
    "\n",
    "def print_index(index):\n",
    "    print(input_output_f(df_without_option_aggregation, path_output)[index])\n",
    "\n",
    "def clean(df):\n",
    "    df = df[['load_time','sample_time','ms_per_token','token_per_sec','prompt_eval_time','ms_per_token.1','token_per_sec.1','eval_time','ms_per_token.2','token_per_sec.2','total_time','name_']]\n",
    "    #Calcule mean_load_time\n",
    "    _load_time = df['load_time'].str.replace(\"ms\", \"\").astype(float)\n",
    "    #Calcule mean_sample_token_per_seconde\n",
    "    _sample_token_per_seconde = df['token_per_sec'].astype(float)\n",
    "    #Calcule mean_prompt_eval_time_token_per_seconde\n",
    "    _prompt_eval_time_token_per_seconde = df['token_per_sec.1'].astype(float)\n",
    "    #Calcule mean_eval_time_token_per_seconde\n",
    "    _eval_time_token_per_seconde = df['token_per_sec.2'].astype(float)\n",
    "    #Calcule mean_total_time_token_per_seconde\n",
    "    step1_mean_total_time_token_per_seconde= df['total_time'].str.replace(\"ms\", \"\").str.replace(\"tokens\",\"\")\n",
    "    step2_1 = step1_mean_total_time_token_per_seconde.apply(lambda x : x.split('/')[0]).astype(float)\n",
    "    step2_2 = step1_mean_total_time_token_per_seconde.apply(lambda x : x.split('/')[1]).astype(float)\n",
    "    \n",
    "    step3 = 1000/(step2_1 / step2_2)\n",
    "    df['_load_time'] = _load_time\n",
    "    df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
    "    df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
    "    df['total_time_token_per_seconde'] = step3\n",
    "    \n",
    "    return df[['name_', '_load_time', '_sample_token_per_seconde','_prompt_eval_time_token_per_seconde','total_time_token_per_seconde']]\n",
    "\n",
    "def print_best(df):\n",
    "    print(\"Best load_time (ms)\")\n",
    "    print(df.sort_values(by='_load_time').iloc[1,:])\n",
    "    print('\\n\\n')\n",
    "\n",
    "\n",
    "    print(\"Best _sample_token_per_seconde\")\n",
    "    print(df.sort_values(by='_sample_token_per_seconde', ascending=False).iloc[1,:])\n",
    "    print('\\n\\n')\n",
    "\n",
    "\n",
    "    print(\"Best _prompt_eval_time_token_per_seconde\")\n",
    "    print(df.sort_values(by='_prompt_eval_time_token_per_seconde', ascending=False).iloc[1,:])\n",
    "    print('\\n\\n')\n",
    "\n",
    "\n",
    "    print(\"Best total_time_token_per_seconde\")\n",
    "    print(df.sort_values(by='total_time_token_per_seconde', ascending=False).iloc[1,:])\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6685e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best load_time (ms)\n",
      "name_                                  input9_log.txt\n",
      "_load_time                                     309.08\n",
      "_sample_token_per_seconde                    10281.72\n",
      "_prompt_eval_time_token_per_seconde             11.36\n",
      "total_time_token_per_seconde                 2.016571\n",
      "Name: 9, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input10_log.txt\n",
      "_load_time                                      867.06\n",
      "_sample_token_per_seconde                     11296.88\n",
      "_prompt_eval_time_token_per_seconde              25.17\n",
      "total_time_token_per_seconde                  3.209608\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input1_log.txt\n",
      "_load_time                                    1131.45\n",
      "_sample_token_per_seconde                     9004.14\n",
      "_prompt_eval_time_token_per_seconde             28.97\n",
      "total_time_token_per_seconde                 3.228248\n",
      "Name: 1, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input2_log.txt\n",
      "_load_time                                     584.48\n",
      "_sample_token_per_seconde                     8032.77\n",
      "_prompt_eval_time_token_per_seconde             44.55\n",
      "total_time_token_per_seconde                 7.099963\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_without_option = clean(df_without_option_aggregation)\n",
    "print_best(df_without_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7145c5a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What are the pros and cons of social media usage in modern society, and how can individuals and communities mitigate the negative effects?', '<|endoftext|>What are the pros and cons of social media usage in modern society, and how can individuals and communities mitigate the negative effects?\\n\\nIt is equally as important as developing any technology of our time. The world we live in today is a world that is fast growing and changing, and it is critical to meet these demands.\\n\\nI have had my own social media habits and the one I now have is social media and one of the best social media tools to be used.\\n\\nIn this tutorial I will show you how to create a social media tracking and social analytics tool. The tool is part of an on-']\n"
     ]
    }
   ],
   "source": [
    "print_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c295ba77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_</th>\n",
       "      <th>_load_time</th>\n",
       "      <th>_sample_token_per_seconde</th>\n",
       "      <th>_prompt_eval_time_token_per_seconde</th>\n",
       "      <th>total_time_token_per_seconde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>input6_log.txt</td>\n",
       "      <td>172.12</td>\n",
       "      <td>8880.99</td>\n",
       "      <td>19.19</td>\n",
       "      <td>4.261193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>input9_log.txt</td>\n",
       "      <td>309.08</td>\n",
       "      <td>10281.72</td>\n",
       "      <td>11.36</td>\n",
       "      <td>2.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>input7_log.txt</td>\n",
       "      <td>316.17</td>\n",
       "      <td>11170.69</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3.728021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>input8_log.txt</td>\n",
       "      <td>446.39</td>\n",
       "      <td>9859.02</td>\n",
       "      <td>26.43</td>\n",
       "      <td>4.293110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input2_log.txt</td>\n",
       "      <td>584.48</td>\n",
       "      <td>8032.77</td>\n",
       "      <td>44.55</td>\n",
       "      <td>7.099963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input3_log.txt</td>\n",
       "      <td>829.74</td>\n",
       "      <td>11924.64</td>\n",
       "      <td>10.66</td>\n",
       "      <td>7.548488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input10_log.txt</td>\n",
       "      <td>867.06</td>\n",
       "      <td>11296.88</td>\n",
       "      <td>25.17</td>\n",
       "      <td>3.209608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input1_log.txt</td>\n",
       "      <td>1131.45</td>\n",
       "      <td>9004.14</td>\n",
       "      <td>28.97</td>\n",
       "      <td>3.228248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>input5_log.txt</td>\n",
       "      <td>1896.97</td>\n",
       "      <td>11063.17</td>\n",
       "      <td>10.54</td>\n",
       "      <td>4.938679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input4_log.txt</td>\n",
       "      <td>2884.60</td>\n",
       "      <td>10654.17</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.214075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name_  _load_time  _sample_token_per_seconde  \\\n",
       "6   input6_log.txt      172.12                    8880.99   \n",
       "9   input9_log.txt      309.08                   10281.72   \n",
       "7   input7_log.txt      316.17                   11170.69   \n",
       "8   input8_log.txt      446.39                    9859.02   \n",
       "2   input2_log.txt      584.48                    8032.77   \n",
       "3   input3_log.txt      829.74                   11924.64   \n",
       "0  input10_log.txt      867.06                   11296.88   \n",
       "1   input1_log.txt     1131.45                    9004.14   \n",
       "5   input5_log.txt     1896.97                   11063.17   \n",
       "4   input4_log.txt     2884.60                   10654.17   \n",
       "\n",
       "   _prompt_eval_time_token_per_seconde  total_time_token_per_seconde  \n",
       "6                                19.19                      4.261193  \n",
       "9                                11.36                      2.016571  \n",
       "7                                 6.20                      3.728021  \n",
       "8                                26.43                      4.293110  \n",
       "2                                44.55                      7.099963  \n",
       "3                                10.66                      7.548488  \n",
       "0                                25.17                      3.209608  \n",
       "1                                28.97                      3.228248  \n",
       "5                                10.54                      4.938679  \n",
       "4                                 9.77                      4.214075  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_option.sort_values(by='_load_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "845d300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_</th>\n",
       "      <th>_load_time</th>\n",
       "      <th>_sample_token_per_seconde</th>\n",
       "      <th>_prompt_eval_time_token_per_seconde</th>\n",
       "      <th>total_time_token_per_seconde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input2_log.txt</td>\n",
       "      <td>584.48</td>\n",
       "      <td>8032.77</td>\n",
       "      <td>44.55</td>\n",
       "      <td>7.099963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>input6_log.txt</td>\n",
       "      <td>172.12</td>\n",
       "      <td>8880.99</td>\n",
       "      <td>19.19</td>\n",
       "      <td>4.261193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input1_log.txt</td>\n",
       "      <td>1131.45</td>\n",
       "      <td>9004.14</td>\n",
       "      <td>28.97</td>\n",
       "      <td>3.228248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>input8_log.txt</td>\n",
       "      <td>446.39</td>\n",
       "      <td>9859.02</td>\n",
       "      <td>26.43</td>\n",
       "      <td>4.293110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>input9_log.txt</td>\n",
       "      <td>309.08</td>\n",
       "      <td>10281.72</td>\n",
       "      <td>11.36</td>\n",
       "      <td>2.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input4_log.txt</td>\n",
       "      <td>2884.60</td>\n",
       "      <td>10654.17</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.214075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>input5_log.txt</td>\n",
       "      <td>1896.97</td>\n",
       "      <td>11063.17</td>\n",
       "      <td>10.54</td>\n",
       "      <td>4.938679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>input7_log.txt</td>\n",
       "      <td>316.17</td>\n",
       "      <td>11170.69</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3.728021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input10_log.txt</td>\n",
       "      <td>867.06</td>\n",
       "      <td>11296.88</td>\n",
       "      <td>25.17</td>\n",
       "      <td>3.209608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input3_log.txt</td>\n",
       "      <td>829.74</td>\n",
       "      <td>11924.64</td>\n",
       "      <td>10.66</td>\n",
       "      <td>7.548488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name_  _load_time  _sample_token_per_seconde  \\\n",
       "2   input2_log.txt      584.48                    8032.77   \n",
       "6   input6_log.txt      172.12                    8880.99   \n",
       "1   input1_log.txt     1131.45                    9004.14   \n",
       "8   input8_log.txt      446.39                    9859.02   \n",
       "9   input9_log.txt      309.08                   10281.72   \n",
       "4   input4_log.txt     2884.60                   10654.17   \n",
       "5   input5_log.txt     1896.97                   11063.17   \n",
       "7   input7_log.txt      316.17                   11170.69   \n",
       "0  input10_log.txt      867.06                   11296.88   \n",
       "3   input3_log.txt      829.74                   11924.64   \n",
       "\n",
       "   _prompt_eval_time_token_per_seconde  total_time_token_per_seconde  \n",
       "2                                44.55                      7.099963  \n",
       "6                                19.19                      4.261193  \n",
       "1                                28.97                      3.228248  \n",
       "8                                26.43                      4.293110  \n",
       "9                                11.36                      2.016571  \n",
       "4                                 9.77                      4.214075  \n",
       "5                                10.54                      4.938679  \n",
       "7                                 6.20                      3.728021  \n",
       "0                                25.17                      3.209608  \n",
       "3                                10.66                      7.548488  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_option.sort_values(by='_sample_token_per_seconde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0e9b2dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_</th>\n",
       "      <th>_load_time</th>\n",
       "      <th>_sample_token_per_seconde</th>\n",
       "      <th>_prompt_eval_time_token_per_seconde</th>\n",
       "      <th>total_time_token_per_seconde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>input7_log.txt</td>\n",
       "      <td>316.17</td>\n",
       "      <td>11170.69</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3.728021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input4_log.txt</td>\n",
       "      <td>2884.60</td>\n",
       "      <td>10654.17</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.214075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>input5_log.txt</td>\n",
       "      <td>1896.97</td>\n",
       "      <td>11063.17</td>\n",
       "      <td>10.54</td>\n",
       "      <td>4.938679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input3_log.txt</td>\n",
       "      <td>829.74</td>\n",
       "      <td>11924.64</td>\n",
       "      <td>10.66</td>\n",
       "      <td>7.548488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>input9_log.txt</td>\n",
       "      <td>309.08</td>\n",
       "      <td>10281.72</td>\n",
       "      <td>11.36</td>\n",
       "      <td>2.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>input6_log.txt</td>\n",
       "      <td>172.12</td>\n",
       "      <td>8880.99</td>\n",
       "      <td>19.19</td>\n",
       "      <td>4.261193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input10_log.txt</td>\n",
       "      <td>867.06</td>\n",
       "      <td>11296.88</td>\n",
       "      <td>25.17</td>\n",
       "      <td>3.209608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>input8_log.txt</td>\n",
       "      <td>446.39</td>\n",
       "      <td>9859.02</td>\n",
       "      <td>26.43</td>\n",
       "      <td>4.293110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input1_log.txt</td>\n",
       "      <td>1131.45</td>\n",
       "      <td>9004.14</td>\n",
       "      <td>28.97</td>\n",
       "      <td>3.228248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input2_log.txt</td>\n",
       "      <td>584.48</td>\n",
       "      <td>8032.77</td>\n",
       "      <td>44.55</td>\n",
       "      <td>7.099963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name_  _load_time  _sample_token_per_seconde  \\\n",
       "7   input7_log.txt      316.17                   11170.69   \n",
       "4   input4_log.txt     2884.60                   10654.17   \n",
       "5   input5_log.txt     1896.97                   11063.17   \n",
       "3   input3_log.txt      829.74                   11924.64   \n",
       "9   input9_log.txt      309.08                   10281.72   \n",
       "6   input6_log.txt      172.12                    8880.99   \n",
       "0  input10_log.txt      867.06                   11296.88   \n",
       "8   input8_log.txt      446.39                    9859.02   \n",
       "1   input1_log.txt     1131.45                    9004.14   \n",
       "2   input2_log.txt      584.48                    8032.77   \n",
       "\n",
       "   _prompt_eval_time_token_per_seconde  total_time_token_per_seconde  \n",
       "7                                 6.20                      3.728021  \n",
       "4                                 9.77                      4.214075  \n",
       "5                                10.54                      4.938679  \n",
       "3                                10.66                      7.548488  \n",
       "9                                11.36                      2.016571  \n",
       "6                                19.19                      4.261193  \n",
       "0                                25.17                      3.209608  \n",
       "8                                26.43                      4.293110  \n",
       "1                                28.97                      3.228248  \n",
       "2                                44.55                      7.099963  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_option.sort_values(by='_prompt_eval_time_token_per_seconde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "32f0cc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_</th>\n",
       "      <th>_load_time</th>\n",
       "      <th>_sample_token_per_seconde</th>\n",
       "      <th>_prompt_eval_time_token_per_seconde</th>\n",
       "      <th>total_time_token_per_seconde</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>input9_log.txt</td>\n",
       "      <td>309.08</td>\n",
       "      <td>10281.72</td>\n",
       "      <td>11.36</td>\n",
       "      <td>2.016571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>input10_log.txt</td>\n",
       "      <td>867.06</td>\n",
       "      <td>11296.88</td>\n",
       "      <td>25.17</td>\n",
       "      <td>3.209608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>input1_log.txt</td>\n",
       "      <td>1131.45</td>\n",
       "      <td>9004.14</td>\n",
       "      <td>28.97</td>\n",
       "      <td>3.228248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>input7_log.txt</td>\n",
       "      <td>316.17</td>\n",
       "      <td>11170.69</td>\n",
       "      <td>6.20</td>\n",
       "      <td>3.728021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>input4_log.txt</td>\n",
       "      <td>2884.60</td>\n",
       "      <td>10654.17</td>\n",
       "      <td>9.77</td>\n",
       "      <td>4.214075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>input6_log.txt</td>\n",
       "      <td>172.12</td>\n",
       "      <td>8880.99</td>\n",
       "      <td>19.19</td>\n",
       "      <td>4.261193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>input8_log.txt</td>\n",
       "      <td>446.39</td>\n",
       "      <td>9859.02</td>\n",
       "      <td>26.43</td>\n",
       "      <td>4.293110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>input5_log.txt</td>\n",
       "      <td>1896.97</td>\n",
       "      <td>11063.17</td>\n",
       "      <td>10.54</td>\n",
       "      <td>4.938679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>input2_log.txt</td>\n",
       "      <td>584.48</td>\n",
       "      <td>8032.77</td>\n",
       "      <td>44.55</td>\n",
       "      <td>7.099963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>input3_log.txt</td>\n",
       "      <td>829.74</td>\n",
       "      <td>11924.64</td>\n",
       "      <td>10.66</td>\n",
       "      <td>7.548488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name_  _load_time  _sample_token_per_seconde  \\\n",
       "9   input9_log.txt      309.08                   10281.72   \n",
       "0  input10_log.txt      867.06                   11296.88   \n",
       "1   input1_log.txt     1131.45                    9004.14   \n",
       "7   input7_log.txt      316.17                   11170.69   \n",
       "4   input4_log.txt     2884.60                   10654.17   \n",
       "6   input6_log.txt      172.12                    8880.99   \n",
       "8   input8_log.txt      446.39                    9859.02   \n",
       "5   input5_log.txt     1896.97                   11063.17   \n",
       "2   input2_log.txt      584.48                    8032.77   \n",
       "3   input3_log.txt      829.74                   11924.64   \n",
       "\n",
       "   _prompt_eval_time_token_per_seconde  total_time_token_per_seconde  \n",
       "9                                11.36                      2.016571  \n",
       "0                                25.17                      3.209608  \n",
       "1                                28.97                      3.228248  \n",
       "7                                 6.20                      3.728021  \n",
       "4                                 9.77                      4.214075  \n",
       "6                                19.19                      4.261193  \n",
       "8                                26.43                      4.293110  \n",
       "5                                10.54                      4.938679  \n",
       "2                                44.55                      7.099963  \n",
       "3                                10.66                      7.548488  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_without_option.sort_values(by='total_time_token_per_seconde')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e7ca51",
   "metadata": {},
   "source": [
    "# 2) ctv_ctk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8bc47de",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : KV_f32\n",
      "mean_load_time : 330.722 ms\n",
      "mean_sample_token_per_seconde : 12319.718 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 32.13 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 11.391 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 12.766 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input8_ctk_ctv_f16_log.txt\n",
      "_load_time                                                 141.35\n",
      "_sample_token_per_seconde                                12876.64\n",
      "_prompt_eval_time_token_per_seconde                         39.22\n",
      "total_time_token_per_seconde                            27.167003\n",
      "Name: 16, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input5_ctk_ctv_f16_log.txt\n",
      "_load_time                                                 143.35\n",
      "_sample_token_per_seconde                                13090.72\n",
      "_prompt_eval_time_token_per_seconde                         50.49\n",
      "total_time_token_per_seconde                            26.336363\n",
      "Name: 10, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input1_ctk_ctv_f16_log.txt\n",
      "_load_time                                                 290.57\n",
      "_sample_token_per_seconde                                 12245.9\n",
      "_prompt_eval_time_token_per_seconde                         47.25\n",
      "total_time_token_per_seconde                            23.415706\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input5_ctk_ctv_f16_log.txt\n",
      "_load_time                                                 143.35\n",
      "_sample_token_per_seconde                                13090.72\n",
      "_prompt_eval_time_token_per_seconde                         50.49\n",
      "total_time_token_per_seconde                            26.336363\n",
      "Name: 10, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def KV(string):\n",
    "    return \"KV_\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(KV)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_ctv_ctk_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a07ece",
   "metadata": {},
   "source": [
    "# 3) Group attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ec3717de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : grp_att_factor_2\n",
      "mean_load_time : 165.125 ms\n",
      "mean_sample_token_per_seconde : 12501.543 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 35.58 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 13.423 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 14.93 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input3_grp_att_n_log.txt\n",
      "_load_time                                               136.88\n",
      "_sample_token_per_seconde                              12150.67\n",
      "_prompt_eval_time_token_per_seconde                       49.68\n",
      "total_time_token_per_seconde                           9.460701\n",
      "Name: 9, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input6_grp_att_w_log.txt\n",
      "_load_time                                               155.58\n",
      "_sample_token_per_seconde                               13328.0\n",
      "_prompt_eval_time_token_per_seconde                       34.14\n",
      "total_time_token_per_seconde                          26.849485\n",
      "Name: 19, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input1_grp_att_w_log.txt\n",
      "_load_time                                               152.74\n",
      "_sample_token_per_seconde                              12896.57\n",
      "_prompt_eval_time_token_per_seconde                       53.94\n",
      "total_time_token_per_seconde                          27.679821\n",
      "Name: 4, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input9_grp_att_w_log.txt\n",
      "_load_time                                               293.82\n",
      "_sample_token_per_seconde                              12725.88\n",
      "_prompt_eval_time_token_per_seconde                       55.29\n",
      "total_time_token_per_seconde                          27.840136\n",
      "Name: 28, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"grp_att\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_grp_att_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3729118",
   "metadata": {},
   "source": [
    "# 4) Keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f47d63d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : keep_0\n",
      "mean_load_time : 316.658 ms\n",
      "mean_sample_token_per_seconde : 11689.775 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 29.813 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 7.986 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 8.96 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best load_time (ms)\n",
      "name_                                  input10_keep_0_log.txt\n",
      "_load_time                                             149.92\n",
      "_sample_token_per_seconde                            11933.17\n",
      "_prompt_eval_time_token_per_seconde                      29.3\n",
      "total_time_token_per_seconde                         9.758405\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input1_keep_all_log.txt\n",
      "_load_time                                              226.21\n",
      "_sample_token_per_seconde                              13875.4\n",
      "_prompt_eval_time_token_per_seconde                      43.02\n",
      "total_time_token_per_seconde                         27.304018\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input6_keep_0_log.txt\n",
      "_load_time                                            154.33\n",
      "_sample_token_per_seconde                           12730.74\n",
      "_prompt_eval_time_token_per_seconde                    43.29\n",
      "total_time_token_per_seconde                        9.616288\n",
      "Name: 18, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input1_keep_all_log.txt\n",
      "_load_time                                              226.21\n",
      "_sample_token_per_seconde                              13875.4\n",
      "_prompt_eval_time_token_per_seconde                      43.02\n",
      "total_time_token_per_seconde                         27.304018\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"keep_\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_keep_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326eafdc",
   "metadata": {},
   "source": [
    "# 5) Min-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "003231f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : min-p 0.01\n",
      "mean_load_time : 289.35 ms\n",
      "mean_sample_token_per_seconde : 11115.159 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 29.864 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 7.911 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 9.084 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input10_min_p_05_log.txt\n",
      "_load_time                                               142.28\n",
      "_sample_token_per_seconde                              12464.17\n",
      "_prompt_eval_time_token_per_seconde                       27.43\n",
      "total_time_token_per_seconde                           8.558754\n",
      "Name: 1, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input5_min_p_05_log.txt\n",
      "_load_time                                              227.45\n",
      "_sample_token_per_seconde                             12782.82\n",
      "_prompt_eval_time_token_per_seconde                      34.45\n",
      "total_time_token_per_seconde                          9.534678\n",
      "Name: 16, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input5_min_p_01_log.txt\n",
      "_load_time                                              153.06\n",
      "_sample_token_per_seconde                              10638.3\n",
      "_prompt_eval_time_token_per_seconde                      39.25\n",
      "total_time_token_per_seconde                          9.234678\n",
      "Name: 15, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input1_min_p_05_log.txt\n",
      "_load_time                                              155.07\n",
      "_sample_token_per_seconde                              12727.5\n",
      "_prompt_eval_time_token_per_seconde                      13.93\n",
      "total_time_token_per_seconde                          9.536761\n",
      "Name: 4, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"min-p\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_min-p_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56609cb",
   "metadata": {},
   "source": [
    "# 6) Mirostat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "905be9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : mirostat 1 / mirostat-lr 0.02 / mirostat-ent 15\n",
      "mean_load_time : 630.363 ms\n",
      "mean_sample_token_per_seconde : 120.991 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 27.774 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 7.643 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 8.133 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input2_mirostat2_br02_ent15_log.txt\n",
      "_load_time                                                           131.0\n",
      "_sample_token_per_seconde                                            51.31\n",
      "_prompt_eval_time_token_per_seconde                                  41.44\n",
      "total_time_token_per_seconde                                      9.569991\n",
      "Name: 64, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input4_mirostat1_br02_ent5_log.txt\n",
      "_load_time                                                         403.17\n",
      "_sample_token_per_seconde                                          134.16\n",
      "_prompt_eval_time_token_per_seconde                                 26.62\n",
      "total_time_token_per_seconde                                    19.367828\n",
      "Name: 102, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input2_mirostat2_br002_ent8_log.txt\n",
      "_load_time                                                          140.32\n",
      "_sample_token_per_seconde                                            74.24\n",
      "_prompt_eval_time_token_per_seconde                                  59.21\n",
      "total_time_token_per_seconde                                     10.541914\n",
      "Name: 63, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input2_mirostat2_br02_ent5_log.txt\n",
      "_load_time                                                         166.42\n",
      "_sample_token_per_seconde                                           74.48\n",
      "_prompt_eval_time_token_per_seconde                                 35.84\n",
      "total_time_token_per_seconde                                    23.556142\n",
      "Name: 66, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"mirostat\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_mirostat_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2f8e90",
   "metadata": {},
   "source": [
    "# 7) NKVO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "184d5eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : disable KV offload\n",
      "mean_load_time : 1667.511 ms\n",
      "mean_sample_token_per_seconde : 10516.053 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 23.552 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 4.479 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 5.313 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input5_nkvo_log.txt\n",
      "_load_time                                          175.96\n",
      "_sample_token_per_seconde                         10844.81\n",
      "_prompt_eval_time_token_per_seconde                  23.97\n",
      "total_time_token_per_seconde                      4.006717\n",
      "Name: 11, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input8_log.txt\n",
      "_load_time                                    2958.84\n",
      "_sample_token_per_seconde                    11675.42\n",
      "_prompt_eval_time_token_per_seconde             14.87\n",
      "total_time_token_per_seconde                 4.873807\n",
      "Name: 16, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input1_nkvo_log.txt\n",
      "_load_time                                          195.58\n",
      "_sample_token_per_seconde                         10961.31\n",
      "_prompt_eval_time_token_per_seconde                  32.93\n",
      "total_time_token_per_seconde                      8.766795\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input1_log.txt\n",
      "_load_time                                     874.39\n",
      "_sample_token_per_seconde                    12040.94\n",
      "_prompt_eval_time_token_per_seconde             29.69\n",
      "total_time_token_per_seconde                 8.518333\n",
      "Name: 2, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"disable KV offload\" in string or \"Normal\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_nkvo_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6502a929",
   "metadata": {},
   "source": [
    "# 8) repeat_last_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25ab518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : repeat last n : 0\n",
      "mean_load_time : 398.63 ms\n",
      "mean_sample_token_per_seconde : 11968.294 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 22.394 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 7.898 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 8.913 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input4_repeat_last_all_log.txt\n",
      "_load_time                                                     139.55\n",
      "_sample_token_per_seconde                                    11866.62\n",
      "_prompt_eval_time_token_per_seconde                             32.31\n",
      "total_time_token_per_seconde                                  9.57201\n",
      "Name: 19, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input5_repeat_last_32_log.txt\n",
      "_load_time                                                    158.61\n",
      "_sample_token_per_seconde                                   13513.51\n",
      "_prompt_eval_time_token_per_seconde                            38.06\n",
      "total_time_token_per_seconde                               26.252959\n",
      "Name: 22, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input7_repeat_last_32_log.txt\n",
      "_load_time                                                    165.29\n",
      "_sample_token_per_seconde                                   13273.16\n",
      "_prompt_eval_time_token_per_seconde                            52.59\n",
      "total_time_token_per_seconde                               16.805959\n",
      "Name: 30, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input2_repeat_last_32_log.txt\n",
      "_load_time                                                    381.69\n",
      "_sample_token_per_seconde                                   12691.97\n",
      "_prompt_eval_time_token_per_seconde                            34.91\n",
      "total_time_token_per_seconde                               25.235566\n",
      "Name: 10, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"repeat last n\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_repeat_last_n_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029084c",
   "metadata": {},
   "source": [
    "# 9) repeat_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b843535c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : repeat penalty : 1\n",
      "mean_load_time : 1128.306 ms\n",
      "mean_sample_token_per_seconde : 9888.492 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 22.673 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 4.536 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 5.419 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input2_repeat_penalty__log.txt\n",
      "_load_time                                                     136.83\n",
      "_sample_token_per_seconde                                     1164.01\n",
      "_prompt_eval_time_token_per_seconde                             28.87\n",
      "total_time_token_per_seconde                                24.996623\n",
      "Name: 11, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input1_repeat_penalty_1_log.txt\n",
      "_load_time                                                       177.6\n",
      "_sample_token_per_seconde                                     11892.02\n",
      "_prompt_eval_time_token_per_seconde                              35.61\n",
      "total_time_token_per_seconde                                  8.570542\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input9_repeat_penalty__log.txt\n",
      "_load_time                                                     136.97\n",
      "_sample_token_per_seconde                                     1173.92\n",
      "_prompt_eval_time_token_per_seconde                              56.2\n",
      "total_time_token_per_seconde                                28.305193\n",
      "Name: 39, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input7_repeat_penalty__log.txt\n",
      "_load_time                                                     162.85\n",
      "_sample_token_per_seconde                                     1170.06\n",
      "_prompt_eval_time_token_per_seconde                             58.67\n",
      "total_time_token_per_seconde                                28.713382\n",
      "Name: 31, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"repeat penalty\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_repeat_penalty_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8fbc0",
   "metadata": {},
   "source": [
    "# 10) Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e4891798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : _np01_ns10_ps10_\n",
      "mean_load_time : 932.942 ms\n",
      "mean_sample_token_per_seconde : 10503.113 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 20.035 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 6.428 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 7.149 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input9_np05_ns2_ps1_log.txt\n",
      "_load_time                                                  140.16\n",
      "_sample_token_per_seconde                                 12874.98\n",
      "_prompt_eval_time_token_per_seconde                          25.71\n",
      "total_time_token_per_seconde                             10.934728\n",
      "Name: 259, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input10_np05_ns1_ps2_log.txt\n",
      "_load_time                                                   170.08\n",
      "_sample_token_per_seconde                                  13670.54\n",
      "_prompt_eval_time_token_per_seconde                           29.41\n",
      "total_time_token_per_seconde                              25.023372\n",
      "Name: 14, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input7_np05_ns2_ps1_log.txt\n",
      "_load_time                                                  176.14\n",
      "_sample_token_per_seconde                                  12137.4\n",
      "_prompt_eval_time_token_per_seconde                          55.66\n",
      "total_time_token_per_seconde                             10.627557\n",
      "Name: 205, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input8_np05_ns2_ps1_log.txt\n",
      "_load_time                                                  520.12\n",
      "_sample_token_per_seconde                                 13313.81\n",
      "_prompt_eval_time_token_per_seconde                          46.91\n",
      "total_time_token_per_seconde                             26.986999\n",
      "Name: 232, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"_np\" in string and \"_ns\" in string and \"_ps\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_split_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79189b5f",
   "metadata": {},
   "source": [
    "# 11) Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a3e00a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : temp : 0\n",
      "mean_load_time : 459.572 ms\n",
      "mean_sample_token_per_seconde : 8323.807 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 21.295 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 8.585 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 9.493 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best load_time (ms)\n",
      "name_                                  input4temp05_log.txt\n",
      "_load_time                                           158.81\n",
      "_sample_token_per_seconde                          10395.01\n",
      "_prompt_eval_time_token_per_seconde                   21.65\n",
      "total_time_token_per_seconde                       8.014002\n",
      "Name: 12, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input3temp5_log.txt\n",
      "_load_time                                          664.54\n",
      "_sample_token_per_seconde                         12365.52\n",
      "_prompt_eval_time_token_per_seconde                  45.18\n",
      "total_time_token_per_seconde                      9.381692\n",
      "Name: 11, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input3temp5_log.txt\n",
      "_load_time                                          664.54\n",
      "_sample_token_per_seconde                         12365.52\n",
      "_prompt_eval_time_token_per_seconde                  45.18\n",
      "total_time_token_per_seconde                      9.381692\n",
      "Name: 11, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input10temp0_log.txt\n",
      "_load_time                                          1270.91\n",
      "_sample_token_per_seconde                           7752.54\n",
      "_prompt_eval_time_token_per_seconde                   12.49\n",
      "total_time_token_per_seconde                       9.652308\n",
      "Name: 1, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"temp\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_temp_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f30bb",
   "metadata": {},
   "source": [
    "# 12) Tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7de2a2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : tfs : 0.1\n",
      "mean_load_time : 1143.974 ms\n",
      "mean_sample_token_per_seconde : 9333.044 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 16.632 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 2.894 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 3.418 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input10_tfs_95_log.txt\n",
      "_load_time                                             168.64\n",
      "_sample_token_per_seconde                            11865.21\n",
      "_prompt_eval_time_token_per_seconde                     22.91\n",
      "total_time_token_per_seconde                         8.123619\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input5_tfs_95_log.txt\n",
      "_load_time                                            738.35\n",
      "_sample_token_per_seconde                           11676.79\n",
      "_prompt_eval_time_token_per_seconde                    14.55\n",
      "total_time_token_per_seconde                        4.146335\n",
      "Name: 35, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input8_tfs_100_log.txt\n",
      "_load_time                                             750.49\n",
      "_sample_token_per_seconde                             11508.8\n",
      "_prompt_eval_time_token_per_seconde                      41.2\n",
      "total_time_token_per_seconde                         8.213185\n",
      "Name: 48, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input6_tfs_100_log.txt\n",
      "_load_time                                             957.34\n",
      "_sample_token_per_seconde                              9440.2\n",
      "_prompt_eval_time_token_per_seconde                     21.09\n",
      "total_time_token_per_seconde                        11.022334\n",
      "Name: 36, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"tfs :\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_tfs_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c6e2e1",
   "metadata": {},
   "source": [
    "#  13) Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3e53e485",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : Threads 1\n",
      "mean_load_time : 225.786 ms\n",
      "mean_sample_token_per_seconde : 13850.154 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 30.543 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 20.29 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 21.524 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input4_thread4_log.txt\n",
      "_load_time                                             130.61\n",
      "_sample_token_per_seconde                            12506.25\n",
      "_prompt_eval_time_token_per_seconde                     21.38\n",
      "total_time_token_per_seconde                         9.895663\n",
      "Name: 15, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input5_thread1_log.txt\n",
      "_load_time                                             203.38\n",
      "_sample_token_per_seconde                            14566.64\n",
      "_prompt_eval_time_token_per_seconde                     34.76\n",
      "total_time_token_per_seconde                        23.724792\n",
      "Name: 16, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input9_thread2_log.txt\n",
      "_load_time                                              179.1\n",
      "_sample_token_per_seconde                            13019.14\n",
      "_prompt_eval_time_token_per_seconde                      50.1\n",
      "total_time_token_per_seconde                        28.705125\n",
      "Name: 29, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input1_thread2_log.txt\n",
      "_load_time                                             146.59\n",
      "_sample_token_per_seconde                            14007.56\n",
      "_prompt_eval_time_token_per_seconde                     44.46\n",
      "total_time_token_per_seconde                        32.134164\n",
      "Name: 4, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"Threads \" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_thraed_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f3a6c",
   "metadata": {},
   "source": [
    "# 14) top -k "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bb44d655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : top-k : 5 \n",
      "mean_load_time : 652.963 ms\n",
      "mean_sample_token_per_seconde : 14635.826 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 29.75 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 9.097 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 10.304 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input10_top_p_01_log.txt\n",
      "_load_time                                               144.74\n",
      "_sample_token_per_seconde                               13466.2\n",
      "_prompt_eval_time_token_per_seconde                       39.64\n",
      "total_time_token_per_seconde                          24.793716\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input1_top_p_01_log.txt\n",
      "_load_time                                               215.6\n",
      "_sample_token_per_seconde                             13513.51\n",
      "_prompt_eval_time_token_per_seconde                      34.31\n",
      "total_time_token_per_seconde                          9.853417\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input3_top_p_05_log.txt\n",
      "_load_time                                              176.43\n",
      "_sample_token_per_seconde                             13365.41\n",
      "_prompt_eval_time_token_per_seconde                      55.48\n",
      "total_time_token_per_seconde                          9.213081\n",
      "Name: 10, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input1_top_p_99_log.txt\n",
      "_load_time                                              144.26\n",
      "_sample_token_per_seconde                              13296.1\n",
      "_prompt_eval_time_token_per_seconde                      27.05\n",
      "total_time_token_per_seconde                         25.301678\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"top-k\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_top-p_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cd9caf",
   "metadata": {},
   "source": [
    "# 15) top-p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fde18a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : top-p : 5 \n",
      "mean_load_time : 627.645 ms\n",
      "mean_sample_token_per_seconde : 12938.256 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 29.724 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 13.569 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 14.807 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input10_top_p_01_log.txt\n",
      "_load_time                                               144.74\n",
      "_sample_token_per_seconde                               13466.2\n",
      "_prompt_eval_time_token_per_seconde                       39.64\n",
      "total_time_token_per_seconde                          24.793716\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input1_top_p_01_log.txt\n",
      "_load_time                                               215.6\n",
      "_sample_token_per_seconde                             13513.51\n",
      "_prompt_eval_time_token_per_seconde                      34.31\n",
      "total_time_token_per_seconde                          9.853417\n",
      "Name: 3, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input3_top_p_05_log.txt\n",
      "_load_time                                              176.43\n",
      "_sample_token_per_seconde                             13365.41\n",
      "_prompt_eval_time_token_per_seconde                      55.48\n",
      "total_time_token_per_seconde                          9.213081\n",
      "Name: 10, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input1_top_p_99_log.txt\n",
      "_load_time                                              144.26\n",
      "_sample_token_per_seconde                              13296.1\n",
      "_prompt_eval_time_token_per_seconde                      27.05\n",
      "total_time_token_per_seconde                         25.301678\n",
      "Name: 5, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"top-p\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_top-p_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0f8166",
   "metadata": {},
   "source": [
    "# 16) Typical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "926731f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option : typicaly : 0 \n",
      "mean_load_time : 661.316 ms\n",
      "mean_sample_token_per_seconde : 11811.744 Tokens per seconde\n",
      "mean_prompt_eval_time_token_per_seconde : 35.932 Tokens per seconde\n",
      "mean_eval_time_token_per_seconde : 14.107 Tokens per seconde\n",
      "mean_total_time_token_per_seconde : 16.039 Tokens per seconde\n",
      "\n",
      " ############################################################## \n",
      "\n",
      "Best load_time (ms)\n",
      "name_                                  input8_typical_9_log.txt\n",
      "_load_time                                               130.89\n",
      "_sample_token_per_seconde                              10519.67\n",
      "_prompt_eval_time_token_per_seconde                       59.27\n",
      "total_time_token_per_seconde                           7.584118\n",
      "Name: 26, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _sample_token_per_seconde\n",
      "name_                                  input2_typical_0_log.txt\n",
      "_load_time                                              1484.04\n",
      "_sample_token_per_seconde                               12543.9\n",
      "_prompt_eval_time_token_per_seconde                       43.01\n",
      "total_time_token_per_seconde                           25.80382\n",
      "Name: 6, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best _prompt_eval_time_token_per_seconde\n",
      "name_                                  input8_typical_9_log.txt\n",
      "_load_time                                               130.89\n",
      "_sample_token_per_seconde                              10519.67\n",
      "_prompt_eval_time_token_per_seconde                       59.27\n",
      "total_time_token_per_seconde                           7.584118\n",
      "Name: 26, dtype: object\n",
      "\n",
      "\n",
      "\n",
      "Best total_time_token_per_seconde\n",
      "name_                                  input5_typical_5_log.txt\n",
      "_load_time                                               139.31\n",
      "_sample_token_per_seconde                               12450.2\n",
      "_prompt_eval_time_token_per_seconde                       35.97\n",
      "total_time_token_per_seconde                          31.723352\n",
      "Name: 16, dtype: object\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_load_time'] = _load_time\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_sample_token_per_seconde'] = _sample_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['_prompt_eval_time_token_per_seconde'] = _prompt_eval_time_token_per_seconde\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_23936\\3361217310.py:44: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['total_time_token_per_seconde'] = step3\n"
     ]
    }
   ],
   "source": [
    "def in_(string):\n",
    "    return \"typicaly\" in string\n",
    "\n",
    "csv = \"summerize.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df = df[df['Option'].apply(in_)]\n",
    "print(\"Option : \" + str(df.iloc[0,0]))\n",
    "print(\"mean_load_time : \" + str(df.iloc[0,1]) + \" ms\")\n",
    "print(\"mean_sample_token_per_seconde : \" + str(df.iloc[0,2]) + \" Tokens per seconde\")\n",
    "print(\"mean_prompt_eval_time_token_per_seconde : \" + str(df.iloc[0,3]) + \" Tokens per seconde\")\n",
    "print(\"mean_eval_time_token_per_seconde : \" + str(df.iloc[0,4]) + \" Tokens per seconde\")\n",
    "print(\"mean_total_time_token_per_seconde : \" + str(df.iloc[0,5]) + \" Tokens per seconde\")\n",
    "#print_index(0)\n",
    "print(\"\\n ############################################################## \\n\")\n",
    "csv = \"gpt2_test_input_typical_aggregation.csv\"\n",
    "df = pd.read_csv(csv, sep=';', encoding='latin1')\n",
    "df_ = clean(df)\n",
    "print_best(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f98c33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
